{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "UFoE Phase 5b-2: GCN4 ColabFold Multimer"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFoE Phase 5b-2: GCN4 ColabFold Multimer\n",
    "\n",
    "**ëª©ì **: ESMFold pseudo-dimerì˜ í•œê³„ë¥¼ ë„˜ì–´ ì§„ì§œ multimer êµ¬ì¡° ì˜ˆì¸¡\n",
    "\n",
    "| Group | ì´ë¦„ | ì„œì—´ (33aa) | ê³¤% | ê±´% |\n",
    "|-------|------|-------------|-----|-----|\n",
    "| A | GCN4_WT | RMKQLEDKVEELLSKNYHLENEVARLKKLVGER | 33% | 45% |\n",
    "| B | GCN4_GON | LMKQLEDIVEELLSLNYHLEINEVALKKLLGEL | 48% | 30% |\n",
    "| C | GCN4_SALT | REKKLEDKEEKLLSKEYKLENEEAKLKKLEGKR | 21% | 67% |\n",
    "\n",
    "**3 Analyses**:\n",
    "1. Inter-chain salt bridge (e-g' registry)\n",
    "2. Core Cb-Cb packing (a,d positions)\n",
    "3. Crossing angle (18-25 expected)\n",
    "\n",
    "**2026-02-13 Young Kang + Claude**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1: ColabFold ì„¤ì¹˜\n",
    "\n",
    "ColabFold + AlphaFold2-multimer ì„¤ì¹˜ (~5ë¶„ ì†Œìš”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "# ColabFold ì„¤ì¹˜\n",
    "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
    "    print(\"[1/4] ColabFold ì„¤ì¹˜ ì¤‘...\")\n",
    "    os.system(\"pip install -q \\\"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\\\"\")\n",
    "    \n",
    "    print(\"[2/4] JAX GPU ì„¤ì¹˜ ì¤‘...\")\n",
    "    os.system(\"pip install -q \\\"jax[cuda12]\\\"\")\n",
    "\n",
    "    print(\"[3/4] Biopython ì„¤ì¹˜ ì¤‘...\")\n",
    "    os.system(\"pip install -q biopython\")\n",
    "\n",
    "    print(\"[4/4] ì„¤ì¹˜ í™•ì¸...\")\n",
    "    os.system(\"touch COLABFOLD_READY\")\n",
    "    print(\"\\n=== ColabFold ì„¤ì¹˜ ì™„ë£Œ! ===\")\n",
    "    print(\"âš ï¸ ëŸ°íƒ€ì„ì´ ì¬ì‹œì‘ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¬ì‹œì‘ í›„ ì´ ì…€ë¶€í„° ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"ColabFold already installed. Skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: ì„¤ì • + í™•ì • ì„œì—´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ê³¤ê°ë¦¬ê±´ 7-3-6-4 ë§¤í•‘\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "AA_TO_TYPE = {\n",
    "    'A': 'gon', 'L': 'gon', 'V': 'gon', 'I': 'gon',\n",
    "    'F': 'gon', 'M': 'gon', 'W': 'gon',\n",
    "    'G': 'gam', 'C': 'gam', 'P': 'gam',\n",
    "    'S': 'ri', 'T': 'ri', 'N': 'ri', 'Q': 'ri', 'H': 'ri', 'Y': 'ri',\n",
    "    'E': 'geon', 'D': 'geon', 'K': 'geon', 'R': 'geon',\n",
    "}\n",
    "\n",
    "MAX_ASA = {\n",
    "    'ALA': 129, 'ARG': 274, 'ASN': 195, 'ASP': 193, 'CYS': 167,\n",
    "    'GLN': 225, 'GLU': 223, 'GLY': 104, 'HIS': 224, 'ILE': 197,\n",
    "    'LEU': 201, 'LYS': 236, 'MET': 224, 'PHE': 240, 'PRO': 159,\n",
    "    'SER': 155, 'THR': 172, 'TRP': 285, 'TYR': 263, 'VAL': 174,\n",
    "}\n",
    "\n",
    "# Heptad register: defgabcdefgabcdefgabcdefgabcdefga\n",
    "HEPTAD = 'defgabcdefgabcdefgabcdefgabcdefga'\n",
    "A_POS = [i for i, h in enumerate(HEPTAD) if h == 'a']  # 4,11,18,25,32\n",
    "D_POS = [i for i, h in enumerate(HEPTAD) if h == 'd']  # 0,7,14,21,28\n",
    "E_POS = [i for i, h in enumerate(HEPTAD) if h == 'e']  # 1,8,15,22,29\n",
    "G_POS = [i for i, h in enumerate(HEPTAD) if h == 'g']  # 3,10,17,24,31\n",
    "CORE_POS = sorted(A_POS + D_POS)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# í™•ì • ì„œì—´ (3 Groups)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "GROUPS = {\n",
    "    'A': {\n",
    "        'name': 'GCN4_WT',\n",
    "        'seq': 'RMKQLEDKVEELLSKNYHLENEVARLKKLVGER',\n",
    "        'desc': 'Wild-type GCN4 (PDB 2ZTA)',\n",
    "    },\n",
    "    'B': {\n",
    "        'name': 'GCN4_GON',\n",
    "        'seq': 'LMKQLEDIVEELLSLNYHLEINEVALKKLLGEL',\n",
    "        'desc': 'ê³¤-ê°•í™”: a,d = L/I 100% hydrophobic core',\n",
    "    },\n",
    "    'C': {\n",
    "        'name': 'GCN4_SALT',\n",
    "        'seq': 'REKKLEDKEEKLLSKEYKLENEEAKLKKLEGKR',\n",
    "        'desc': 'ê±´-ê°•í™”: e=E, g=K 100% salt bridge max',\n",
    "    },\n",
    "}\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "OUTPUT_DIR = Path('ufoe_5b2_output')\n",
    "PDB_DIR = OUTPUT_DIR / 'pdb'\n",
    "FASTA_DIR = OUTPUT_DIR / 'fasta'\n",
    "for d in [OUTPUT_DIR, PDB_DIR, FASTA_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ì„œì—´ í™•ì¸\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print('=' * 70)\n",
    "print('  UFoE Phase 5b-2: GCN4 í™•ì • ì„œì—´')\n",
    "print('=' * 70)\n",
    "print()\n",
    "\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    g = GROUPS[gname]\n",
    "    seq = g['seq']\n",
    "    types = [AA_TO_TYPE[aa] for aa in seq]\n",
    "    c = Counter(types)\n",
    "    n = len(seq)\n",
    "\n",
    "    core_aa = [seq[i] for i in CORE_POS if i < n]\n",
    "    core_gon = sum(1 for aa in core_aa if AA_TO_TYPE[aa] == 'gon')\n",
    "\n",
    "    eg_aa = [seq[i] for i in sorted(E_POS + G_POS) if i < n]\n",
    "    eg_geon = sum(1 for aa in eg_aa if AA_TO_TYPE[aa] == 'geon')\n",
    "\n",
    "    print(f\"  Group {gname}: {g['desc']}\")\n",
    "    print(f\"  [{g['name']}] {seq} ({n}aa)\")\n",
    "    print(f\"    ê³¤={c['gon']/n:.0%} ê°={c['gam']/n:.0%} ë¦¬={c['ri']/n:.0%} ê±´={c['geon']/n:.0%}\")\n",
    "    print(f\"    a,d core: {''.join(core_aa)} (ê³¤ {core_gon/len(core_aa)*100:.0f}%)\")\n",
    "    print(f\"    e,g salt: {''.join(eg_aa)} (ê±´ {eg_geon/len(eg_aa)*100:.0f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3: ColabFold Multimer ì˜ˆì¸¡ ì‹¤í–‰\n",
    "\n",
    "ê° ê·¸ë£¹ì˜ homodimerë¥¼ AlphaFold2-multimer-v3ë¡œ ì˜ˆì¸¡ (~10-15ë¶„/ê·¸ë£¹)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import subprocess\n",
    "\n",
    "# FASTA íŒŒì¼ ìƒì„± (ColabFold multimer í˜•ì‹: seq:seq)\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    g = GROUPS[gname]\n",
    "    seq = g['seq']\n",
    "    fasta_path = FASTA_DIR / f\"{g['name']}.fasta\"\n",
    "    with open(fasta_path, 'w') as f:\n",
    "        f.write(f\">{g['name']}\\n{seq}:{seq}\\n\")\n",
    "    print(f\"  {gname}: {fasta_path}\")\n",
    "\n",
    "# ë°°ì¹˜ FASTA\n",
    "batch_fasta = FASTA_DIR / 'gcn4_5b2_all.fasta'\n",
    "with open(batch_fasta, 'w') as f:\n",
    "    for gname in ['A', 'B', 'C']:\n",
    "        g = GROUPS[gname]\n",
    "        f.write(f\">{g['name']}\\n{g['seq']}:{g['seq']}\\n\")\n",
    "\n",
    "print(f\"\\n  ë°°ì¹˜ FASTA: {batch_fasta}\")\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"  ColabFold Multimer ì˜ˆì¸¡ ì‹œì‘\")\n",
    "print(f\"{'=' * 70}\\n\")\n",
    "\n",
    "# ColabFold ë°°ì¹˜ ì‹¤í–‰\n",
    "result_dir = OUTPUT_DIR / 'colabfold_results'\n",
    "result_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    'colabfold_batch',\n",
    "    str(batch_fasta),\n",
    "    str(result_dir),\n",
    "    '--num-models', '5',\n",
    "    '--num-recycle', '3',\n",
    "    '--model-type', 'alphafold2_multimer_v3',\n",
    "    '--pair-mode', 'unpaired_paired',\n",
    "]\n",
    "\n",
    "print(f\"  ëª…ë ¹: {' '.join(cmd)}\")\n",
    "print(f\"  ì˜ˆìƒ ì†Œìš”: ~30-45ë¶„ (3 ê·¸ë£¹ Ã— 5 ëª¨ë¸)\")\n",
    "print(f\"  ê²°ê³¼ ë””ë ‰í† ë¦¬: {result_dir}\")\n",
    "print()\n",
    "\n",
    "process = subprocess.run(cmd, capture_output=False, text=True)\n",
    "\n",
    "if process.returncode == 0:\n",
    "    print(\"\\n\\n=== ColabFold ì˜ˆì¸¡ ì™„ë£Œ! ===\")\n",
    "else:\n",
    "    print(f\"\\n\\nâš ï¸ ColabFold ì˜¤ë¥˜ ë°œìƒ (returncode={process.returncode})\")\n",
    "    print(\"ì•„ë˜ì˜ ê°œë³„ ì‹¤í–‰ ì…€ì„ ì‚¬ìš©í•´ ë³´ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ëŒ€ì•ˆ) ê°œë³„ ê·¸ë£¹ ì‹¤í–‰\n",
    "\n",
    "ë°°ì¹˜ ì‹¤í–‰ì— ë¬¸ì œê°€ ìˆì„ ê²½ìš°, ê·¸ë£¹ë³„ë¡œ ê°œë³„ ì‹¤í–‰:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë³„ ê·¸ë£¹ ì‹¤í–‰ (í•„ìš”ì‹œ)\n",
    "# ì‹¤í–‰í•  ê·¸ë£¹ì„ ì„ íƒí•˜ì„¸ìš”: 'A', 'B', ë˜ëŠ” 'C'\n",
    "RUN_GROUP = 'A'  # <-- ë³€ê²½í•˜ì—¬ ì‹¤í–‰\n",
    "\n",
    "g = GROUPS[RUN_GROUP]\n",
    "fasta_path = FASTA_DIR / f\"{g['name']}.fasta\"\n",
    "group_result_dir = OUTPUT_DIR / 'colabfold_results'\n",
    "group_result_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Group {RUN_GROUP} ({g['name']}) ê°œë³„ ì‹¤í–‰\")\n",
    "print(f\"ì„œì—´: {g['seq']}\")\n",
    "print(f\"FASTA: {fasta_path}\")\n",
    "print()\n",
    "\n",
    "!colabfold_batch {str(fasta_path)} {str(group_result_dir)} \\\n",
    "    --num-models 5 --num-recycle 3 \\\n",
    "    --model-type alphafold2_multimer_v3 \\\n",
    "    --pair-mode unpaired_paired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 4: ê²°ê³¼ PDB íŒŒì¼ ì°¾ê¸°\n",
    "\n",
    "ColabFold ì¶œë ¥ì—ì„œ best-ranked PDB íŒŒì¼ ìë™ íƒìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "result_dir = OUTPUT_DIR / 'colabfold_results'\n",
    "\n",
    "# ColabFold ì¶œë ¥ êµ¬ì¡°: {name}_relaxed_rank_001_*.pdb ë˜ëŠ” {name}_unrelaxed_rank_001_*.pdb\n",
    "pdb_files = {}\n",
    "\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    g = GROUPS[gname]\n",
    "    name = g['name']\n",
    "\n",
    "    # rank_001 (best) PDB ì°¾ê¸° â€” relaxed ìš°ì„ , ì—†ìœ¼ë©´ unrelaxed\n",
    "    patterns = [\n",
    "        str(result_dir / f\"{name}_relaxed_rank_001_*.pdb\"),\n",
    "        str(result_dir / f\"{name}_unrelaxed_rank_001_*.pdb\"),\n",
    "        str(result_dir / f\"{name}*rank_001*.pdb\"),\n",
    "        str(result_dir / f\"{name}*rank001*.pdb\"),\n",
    "        str(result_dir / f\"{name}*.pdb\"),\n",
    "    ]\n",
    "\n",
    "    found = None\n",
    "    for pat in patterns:\n",
    "        matches = sorted(glob.glob(pat))\n",
    "        if matches:\n",
    "            found = matches[0]\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        pdb_files[gname] = found\n",
    "        print(f\"  Group {gname} ({name}): {found}\")\n",
    "    else:\n",
    "        print(f\"  Group {gname} ({name}): âš ï¸ PDB not found\")\n",
    "        # ì‚¬ìš©ìê°€ ìˆ˜ë™ ê²½ë¡œ ì§€ì • ê°€ëŠ¥\n",
    "        # pdb_files[gname] = '/path/to/your/pdb'\n",
    "\n",
    "print(f\"\\n  PDB íŒŒì¼ {len(pdb_files)}/3 ë°œê²¬\")\n",
    "\n",
    "if len(pdb_files) < 3:\n",
    "    print(\"\\n  âš ï¸ ëˆ„ë½ëœ PDB íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"  ê²°ê³¼ ë””ë ‰í† ë¦¬ ë‚´ìš©:\")\n",
    "    for f in sorted(glob.glob(str(result_dir / '*'))):\n",
    "        print(f\"    {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ìˆ˜ë™ ê²½ë¡œ ì§€ì •)\n",
    "\n",
    "ìë™ íƒìƒ‰ì´ ì‹¤íŒ¨í•œ ê²½ìš°, ì•„ë˜ ì…€ì—ì„œ ì§ì ‘ PDB ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ê²½ìš°ë§Œ ì‹¤í–‰: ìˆ˜ë™ìœ¼ë¡œ PDB ê²½ë¡œ ì§€ì •\n",
    "# pdb_files['A'] = 'ufoe_5b2_output/colabfold_results/GCN4_WT_relaxed_rank_001_model_1.pdb'\n",
    "# pdb_files['B'] = 'ufoe_5b2_output/colabfold_results/GCN4_GON_relaxed_rank_001_model_1.pdb'\n",
    "# pdb_files['C'] = 'ufoe_5b2_output/colabfold_results/GCN4_SALT_relaxed_rank_001_model_1.pdb'\n",
    "\n",
    "print(\"í˜„ì¬ PDB ê²½ë¡œ:\")\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    path = pdb_files.get(gname, 'NOT SET')\n",
    "    exists = os.path.exists(path) if path != 'NOT SET' else False\n",
    "    print(f\"  Group {gname}: {path} {'âœ…' if exists else 'âŒ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 5: pLDDT + pTM ì ìˆ˜ í™•ì¸\n",
    "\n",
    "ColabFold JSON ê²°ê³¼ì—ì„œ confidence ì ìˆ˜ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "\n",
    "parser = PDBParser(QUIET=True)\n",
    "confidence_data = {}\n",
    "\n",
    "print('=' * 70)\n",
    "print('  pLDDT + Chainë³„ ì ìˆ˜')\n",
    "print('=' * 70)\n",
    "print()\n",
    "\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    if gname not in pdb_files:\n",
    "        print(f\"  Group {gname}: SKIP (no PDB)\")\n",
    "        continue\n",
    "\n",
    "    pdb_path = pdb_files[gname]\n",
    "    g = GROUPS[gname]\n",
    "\n",
    "    structure = parser.get_structure(gname, pdb_path)\n",
    "    chains = list(structure[0].get_chains())\n",
    "\n",
    "    chain_plddts = {}\n",
    "    all_plddts = []\n",
    "\n",
    "    for chain in chains:\n",
    "        chain_id = chain.id\n",
    "        plddts = []\n",
    "        for res in chain.get_residues():\n",
    "            for atom in res:\n",
    "                if atom.name == 'CA':\n",
    "                    plddts.append(atom.bfactor)\n",
    "                    break\n",
    "\n",
    "        if plddts:\n",
    "            # bfactorê°€ 0-1 ë²”ìœ„ë©´ 100x\n",
    "            if max(plddts) <= 1.0:\n",
    "                plddts = [p * 100 for p in plddts]\n",
    "            chain_plddts[chain_id] = round(np.mean(plddts), 1)\n",
    "            all_plddts.extend(plddts)\n",
    "\n",
    "    total_plddt = round(np.mean(all_plddts), 1) if all_plddts else 0\n",
    "\n",
    "    confidence_data[gname] = {\n",
    "        'chains': chain_plddts,\n",
    "        'total': total_plddt,\n",
    "        'n_chains': len(chains),\n",
    "    }\n",
    "\n",
    "    print(f\"  Group {gname} ({g['name']}): {len(chains)} chains\")\n",
    "    for cid, plddt in chain_plddts.items():\n",
    "        print(f\"    Chain {cid}: pLDDT = {plddt}\")\n",
    "    print(f\"    Total pLDDT = {total_plddt}\")\n",
    "\n",
    "    # JSON ì ìˆ˜ íŒŒì¼ë„ í™•ì¸\n",
    "    json_pattern = pdb_path.replace('.pdb', '').replace('_relaxed', '').replace('_unrelaxed', '')\n",
    "    for jf in glob.glob(str(result_dir / f\"{g['name']}*scores*.json\")):\n",
    "        with open(jf) as f:\n",
    "            scores = json.load(f)\n",
    "        if 'ptm' in scores:\n",
    "            print(f\"    pTM = {scores['ptm']:.3f}\")\n",
    "        if 'iptm' in scores:\n",
    "            print(f\"    ipTM = {scores['iptm']:.3f}\")\n",
    "        if 'ptm' in scores and 'iptm' in scores:\n",
    "            ranking = 0.8 * scores['iptm'] + 0.2 * scores['ptm']\n",
    "            print(f\"    Ranking score (0.8*ipTM + 0.2*pTM) = {ranking:.3f}\")\n",
    "            confidence_data[gname]['ptm'] = round(scores['ptm'], 3)\n",
    "            confidence_data[gname]['iptm'] = round(scores['iptm'], 3)\n",
    "            confidence_data[gname]['ranking'] = round(ranking, 3)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 6: ë¶„ì„ 1 â€” Inter-chain Salt Bridge ê²€ì¶œ\n",
    "\n",
    "ColabFold ì§„ì§œ multimerì—ì„œ e-g' registry salt bridge ê²€ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "\n",
    "def detect_salt_bridges_multimer(pdb_file, seq, cutoff=4.0):\n",
    "    \"\"\"ColabFold multimer PDBì—ì„œ inter-chain salt bridge ê²€ì¶œ.\n",
    "\n",
    "    ColabFold multimer: ë³„ë„ chain A, Bë¡œ ì¶œë ¥ë¨.\n",
    "    \"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('s', pdb_file)\n",
    "    chains = list(structure[0].get_chains())\n",
    "\n",
    "    if len(chains) < 2:\n",
    "        print(f\"    âš ï¸ Chain 2ê°œ ë¯¸ë§Œ: {len(chains)}ê°œ\")\n",
    "        return {'all': [], 'total': 0, 'canonical': [], 'canonical_count': 0}\n",
    "\n",
    "    chain_a_res = list(chains[0].get_residues())\n",
    "    chain_b_res = list(chains[1].get_residues())\n",
    "\n",
    "    neg_atoms_map = {'GLU': ['OE1', 'OE2'], 'ASP': ['OD1', 'OD2']}\n",
    "    pos_atoms_map = {'LYS': ['NZ'], 'ARG': ['NH1', 'NH2']}\n",
    "\n",
    "    bridges = []\n",
    "\n",
    "    def check_pair(res_i, i_idx, res_j, j_idx, direction):\n",
    "        rn_i = res_i.get_resname()\n",
    "        rn_j = res_j.get_resname()\n",
    "\n",
    "        # neg(i) â†” pos(j)\n",
    "        neg_atoms = neg_atoms_map.get(rn_i, [])\n",
    "        pos_atoms = pos_atoms_map.get(rn_j, [])\n",
    "\n",
    "        for na in neg_atoms:\n",
    "            for pa in pos_atoms:\n",
    "                if na in res_i and pa in res_j:\n",
    "                    d = res_i[na] - res_j[pa]\n",
    "                    if d < cutoff:\n",
    "                        h_i = HEPTAD[i_idx] if i_idx < len(HEPTAD) else '?'\n",
    "                        h_j = HEPTAD[j_idx] if j_idx < len(HEPTAD) else '?'\n",
    "                        aa_i = seq[i_idx] if i_idx < len(seq) else '?'\n",
    "                        aa_j = seq[j_idx] if j_idx < len(seq) else '?'\n",
    "                        canonical = (h_i in ('e', 'g') and h_j in ('e', 'g'))\n",
    "                        bridges.append({\n",
    "                            'chain_a_pos': i_idx + 1 if direction == 'AB' else j_idx + 1,\n",
    "                            'chain_b_pos': j_idx + 1 if direction == 'AB' else i_idx + 1,\n",
    "                            'aa_a': aa_i if direction == 'AB' else aa_j,\n",
    "                            'aa_b': aa_j if direction == 'AB' else aa_i,\n",
    "                            'heptad_a': h_i if direction == 'AB' else h_j,\n",
    "                            'heptad_b': h_j if direction == 'AB' else h_i,\n",
    "                            'atoms': f\"{na}-{pa}\" if direction == 'AB' else f\"{pa}-{na}\",\n",
    "                            'dist': round(d, 2),\n",
    "                            'canonical_eg': canonical,\n",
    "                            'direction': direction,\n",
    "                        })\n",
    "\n",
    "    # A(neg) â†’ B(pos)\n",
    "    for i, res_a in enumerate(chain_a_res):\n",
    "        for j, res_b in enumerate(chain_b_res):\n",
    "            check_pair(res_a, i, res_b, j, 'AB')\n",
    "\n",
    "    # B(neg) â†’ A(pos)\n",
    "    for j, res_b in enumerate(chain_b_res):\n",
    "        for i, res_a in enumerate(chain_a_res):\n",
    "            check_pair(res_b, j, res_a, i, 'BA')\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±° (ê°™ì€ ì”ê¸° ìŒ â†’ ê°€ì¥ ê°€ê¹Œìš´ ê²ƒë§Œ)\n",
    "    unique = {}\n",
    "    for b in bridges:\n",
    "        key = (b['chain_a_pos'], b['chain_b_pos'])\n",
    "        rev_key = (b['chain_b_pos'], b['chain_a_pos'])\n",
    "        if key not in unique or b['dist'] < unique[key]['dist']:\n",
    "            unique[key] = b\n",
    "        if rev_key not in unique or b['dist'] < unique[rev_key]['dist']:\n",
    "            unique[rev_key] = b\n",
    "\n",
    "    result = sorted(unique.values(), key=lambda x: x['dist'])\n",
    "    # ì§„ì§œ ìœ ì¼í•œ ìŒë§Œ ë‚¨ê¸°ê¸°\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for b in result:\n",
    "        pair = tuple(sorted([b['chain_a_pos'], b['chain_b_pos']]))\n",
    "        if pair not in seen:\n",
    "            seen.add(pair)\n",
    "            final.append(b)\n",
    "\n",
    "    canonical = [b for b in final if b['canonical_eg']]\n",
    "\n",
    "    return {\n",
    "        'all': final,\n",
    "        'total': len(final),\n",
    "        'canonical': canonical,\n",
    "        'canonical_count': len(canonical),\n",
    "    }\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ì‹¤í–‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "salt_bridge_results = {}\n",
    "\n",
    "print('=' * 70)\n",
    "print('  ë¶„ì„ 1: Inter-chain Salt Bridge')\n",
    "print('=' * 70)\n",
    "print()\n",
    "\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    if gname not in pdb_files:\n",
    "        print(f\"  Group {gname}: SKIP\")\n",
    "        continue\n",
    "\n",
    "    g = GROUPS[gname]\n",
    "    print(f\"  â”€â”€ Group {gname}: {g['name']} â”€â”€\")\n",
    "\n",
    "    sb = detect_salt_bridges_multimer(pdb_files[gname], g['seq'])\n",
    "    salt_bridge_results[gname] = sb\n",
    "\n",
    "    print(f\"    Total: {sb['total']}\")\n",
    "    print(f\"    Canonical (e-g'): {sb['canonical_count']}\")\n",
    "\n",
    "    for b in sb['all'][:10]:\n",
    "        tag = ' â˜… canonical' if b['canonical_eg'] else ''\n",
    "        print(f\"      {b['aa_a']}{b['chain_a_pos']}({b['heptad_a']}) â€” \"\n",
    "              f\"{b['aa_b']}{b['chain_b_pos']}({b['heptad_b']}) \"\n",
    "              f\"dist={b['dist']}Ã… [{b['atoms']}]{tag}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 7: ë¶„ì„ 2 â€” Core Cb-Cb Packing (a,d positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_core_packing_multimer(pdb_file, seq):\n",
    "    \"\"\"ColabFold multimer PDBì—ì„œ a,d ìœ„ì¹˜ inter-chain Cb-Cb ê±°ë¦¬.\n",
    "\n",
    "    ì½”ì¼ë“œì½”ì¼ ì •ìƒ: a<->a' 6-8A, d<->d' 6-8A, a<->d' 5-7A.\n",
    "    \"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('s', pdb_file)\n",
    "    chains = list(structure[0].get_chains())\n",
    "\n",
    "    if len(chains) < 2:\n",
    "        return {'error': f'Need 2 chains, got {len(chains)}'}\n",
    "\n",
    "    res_a = list(chains[0].get_residues())\n",
    "    res_b = list(chains[1].get_residues())\n",
    "\n",
    "    def get_cb(res):\n",
    "        if 'CB' in res:\n",
    "            return res['CB'].get_vector().get_array()\n",
    "        if 'CA' in res:\n",
    "            return res['CA'].get_vector().get_array()\n",
    "        return None\n",
    "\n",
    "    distances = {'a_a': [], 'd_d': [], 'a_d': [], 'd_a': []}\n",
    "    n_a = min(len(seq), len(res_a))\n",
    "    n_b = min(len(seq), len(res_b))\n",
    "\n",
    "    # a(chain A) vs a(chain B)\n",
    "    for ia in A_POS:\n",
    "        if ia >= n_a:\n",
    "            continue\n",
    "        cb_a = get_cb(res_a[ia])\n",
    "        if cb_a is None:\n",
    "            continue\n",
    "        for ib in A_POS:\n",
    "            if ib >= n_b:\n",
    "                continue\n",
    "            cb_b = get_cb(res_b[ib])\n",
    "            if cb_b is not None:\n",
    "                distances['a_a'].append(np.linalg.norm(np.array(cb_a) - np.array(cb_b)))\n",
    "\n",
    "    # d(chain A) vs d(chain B)\n",
    "    for ia in D_POS:\n",
    "        if ia >= n_a:\n",
    "            continue\n",
    "        cb_a = get_cb(res_a[ia])\n",
    "        if cb_a is None:\n",
    "            continue\n",
    "        for ib in D_POS:\n",
    "            if ib >= n_b:\n",
    "                continue\n",
    "            cb_b = get_cb(res_b[ib])\n",
    "            if cb_b is not None:\n",
    "                distances['d_d'].append(np.linalg.norm(np.array(cb_a) - np.array(cb_b)))\n",
    "\n",
    "    # a(A) vs d(B), d(A) vs a(B)\n",
    "    for ia in A_POS:\n",
    "        if ia >= n_a:\n",
    "            continue\n",
    "        cb_a = get_cb(res_a[ia])\n",
    "        if cb_a is None:\n",
    "            continue\n",
    "        for ib in D_POS:\n",
    "            if ib >= n_b:\n",
    "                continue\n",
    "            cb_b = get_cb(res_b[ib])\n",
    "            if cb_b is not None:\n",
    "                distances['a_d'].append(np.linalg.norm(np.array(cb_a) - np.array(cb_b)))\n",
    "\n",
    "    for ia in D_POS:\n",
    "        if ia >= n_a:\n",
    "            continue\n",
    "        cb_a = get_cb(res_a[ia])\n",
    "        if cb_a is None:\n",
    "            continue\n",
    "        for ib in A_POS:\n",
    "            if ib >= n_b:\n",
    "                continue\n",
    "            cb_b = get_cb(res_b[ib])\n",
    "            if cb_b is not None:\n",
    "                distances['d_a'].append(np.linalg.norm(np.array(cb_a) - np.array(cb_b)))\n",
    "\n",
    "    stats = {}\n",
    "    for key, vals in distances.items():\n",
    "        if vals:\n",
    "            stats[key] = {\n",
    "                'min': round(min(vals), 2),\n",
    "                'mean': round(np.mean(vals), 2),\n",
    "                'std': round(np.std(vals), 2),\n",
    "                'n': len(vals),\n",
    "            }\n",
    "        else:\n",
    "            stats[key] = None\n",
    "\n",
    "    # Same-heptad ìœ„ì¹˜ ë¹„êµ (a_i(A) vs a_i(B), d_i(A) vs d_i(B))\n",
    "    same_heptad = []\n",
    "    for idx, pos in enumerate(A_POS):\n",
    "        if pos >= n_a or pos >= n_b:\n",
    "            continue\n",
    "        cb_a = get_cb(res_a[pos])\n",
    "        cb_b = get_cb(res_b[pos])\n",
    "        if cb_a is not None and cb_b is not None:\n",
    "            d = np.linalg.norm(np.array(cb_a) - np.array(cb_b))\n",
    "            same_heptad.append({\n",
    "                'type': 'a', 'heptad_idx': idx, 'pos': pos + 1,\n",
    "                'aa_a': seq[pos], 'aa_b': seq[pos], 'dist': round(d, 2),\n",
    "            })\n",
    "\n",
    "    for idx, pos in enumerate(D_POS):\n",
    "        if pos >= n_a or pos >= n_b:\n",
    "            continue\n",
    "        cb_a = get_cb(res_a[pos])\n",
    "        cb_b = get_cb(res_b[pos])\n",
    "        if cb_a is not None and cb_b is not None:\n",
    "            d = np.linalg.norm(np.array(cb_a) - np.array(cb_b))\n",
    "            same_heptad.append({\n",
    "                'type': 'd', 'heptad_idx': idx, 'pos': pos + 1,\n",
    "                'aa_a': seq[pos], 'aa_b': seq[pos], 'dist': round(d, 2),\n",
    "            })\n",
    "\n",
    "    return {'all_distances': stats, 'same_heptad': same_heptad}\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ì‹¤í–‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "core_packing_results = {}\n",
    "\n",
    "print('=' * 70)\n",
    "print('  ë¶„ì„ 2: Core Cb-Cb Packing (a,d positions)')\n",
    "print('=' * 70)\n",
    "print()\n",
    "\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    if gname not in pdb_files:\n",
    "        continue\n",
    "\n",
    "    g = GROUPS[gname]\n",
    "    print(f\"  â”€â”€ Group {gname}: {g['name']} â”€â”€\")\n",
    "\n",
    "    cp = analyze_core_packing_multimer(pdb_files[gname], g['seq'])\n",
    "    core_packing_results[gname] = cp\n",
    "\n",
    "    if 'error' in cp:\n",
    "        print(f\"    Error: {cp['error']}\")\n",
    "        continue\n",
    "\n",
    "    for key in ['a_a', 'd_d', 'a_d']:\n",
    "        s = cp['all_distances'].get(key)\n",
    "        if s:\n",
    "            print(f\"    {key}: min={s['min']}A mean={s['mean']}A std={s['std']}A\")\n",
    "\n",
    "    print(f\"    Same-heptad (closest 5):\")\n",
    "    for sh in sorted(cp['same_heptad'], key=lambda x: x['dist'])[:5]:\n",
    "        print(f\"      {sh['type']}{sh['pos']}: {sh['aa_a']}â†”{sh['aa_b']} = {sh['dist']}A\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 8: ë¶„ì„ 3 â€” Crossing Angle + Inter-helix Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_crossing_angle_multimer(pdb_file, seq):\n",
    "    \"\"\"PCAë¡œ ë‘ chainì˜ helix ì¶• ì‚¬ì´ crossing angle ê³„ì‚°.\n",
    "\n",
    "    GCN4 coiled-coil ê¸°ëŒ€ê°’: 18-25 degrees, parallel.\n",
    "    \"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('s', pdb_file)\n",
    "    chains = list(structure[0].get_chains())\n",
    "\n",
    "    if len(chains) < 2:\n",
    "        return {'error': f'Need 2 chains, got {len(chains)}'}\n",
    "\n",
    "    # CA ì¢Œí‘œ ìˆ˜ì§‘\n",
    "    def get_ca_coords(chain):\n",
    "        coords = []\n",
    "        for res in chain.get_residues():\n",
    "            if 'CA' in res:\n",
    "                coords.append(res['CA'].get_vector().get_array())\n",
    "        return np.array(coords)\n",
    "\n",
    "    ca_a = get_ca_coords(chains[0])\n",
    "    ca_b = get_ca_coords(chains[1])\n",
    "\n",
    "    if len(ca_a) < 5 or len(ca_b) < 5:\n",
    "        return {'error': f'Not enough CA atoms: {len(ca_a)}, {len(ca_b)}'}\n",
    "\n",
    "    def helix_axis(coords):\n",
    "        center = np.mean(coords, axis=0)\n",
    "        centered = coords - center\n",
    "        cov = np.cov(centered.T)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "        axis = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "        return axis, center\n",
    "\n",
    "    axis_a, center_a = helix_axis(ca_a)\n",
    "    axis_b, center_b = helix_axis(ca_b)\n",
    "\n",
    "    # Crossing angle\n",
    "    cos_angle = np.dot(axis_a, axis_b) / (np.linalg.norm(axis_a) * np.linalg.norm(axis_b))\n",
    "    cos_angle = max(-1, min(1, cos_angle))\n",
    "    crossing = np.degrees(np.arccos(abs(cos_angle)))\n",
    "\n",
    "    is_parallel = cos_angle > 0\n",
    "    inter_dist = np.linalg.norm(center_a - center_b)\n",
    "\n",
    "    return {\n",
    "        'crossing_angle': round(crossing, 1),\n",
    "        'is_parallel': is_parallel,\n",
    "        'inter_helix_dist': round(inter_dist, 1),\n",
    "        'coiled_coil': crossing < 30 and is_parallel,\n",
    "    }\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ì‹¤í–‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "crossing_angle_results = {}\n",
    "\n",
    "print('=' * 70)\n",
    "print('  ë¶„ì„ 3: Crossing Angle + Inter-helix Distance')\n",
    "print('=' * 70)\n",
    "print()\n",
    "\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    if gname not in pdb_files:\n",
    "        continue\n",
    "\n",
    "    g = GROUPS[gname]\n",
    "    print(f\"  â”€â”€ Group {gname}: {g['name']} â”€â”€\")\n",
    "\n",
    "    ca = calc_crossing_angle_multimer(pdb_files[gname], g['seq'])\n",
    "    crossing_angle_results[gname] = ca\n",
    "\n",
    "    if 'error' in ca:\n",
    "        print(f\"    Error: {ca['error']}\")\n",
    "    else:\n",
    "        cc_ok = 'âœ…' if ca['coiled_coil'] else 'âŒ'\n",
    "        par = 'âœ… parallel' if ca['is_parallel'] else 'âŒ anti-parallel'\n",
    "        in_range = 'âœ…' if 18 <= ca['crossing_angle'] <= 25 else 'âš ï¸'\n",
    "        print(f\"    Crossing angle: {ca['crossing_angle']}Â° {in_range}\")\n",
    "        print(f\"    Direction: {par}\")\n",
    "        print(f\"    Inter-helix dist: {ca['inter_helix_dist']}A\")\n",
    "        print(f\"    Coiled-coil: {cc_ok}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 9: ë³´ë„ˆìŠ¤ â€” SASA Burial Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser, ShrakeRupley\n",
    "\n",
    "def calc_burial_ratio_multimer(pdb_file, seq):\n",
    "    \"\"\"a,d core vs surface SASA ë¹„ìœ¨ (ColabFold multimer).\n",
    "\n",
    "    burial_ratio < 0.6 = ì½”ì–´ ë§¤ëª° ì„±ê³µ\n",
    "    \"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('s', pdb_file)\n",
    "    model = structure[0]\n",
    "\n",
    "    # ì „ì²´ complex SASA ê³„ì‚°\n",
    "    sr = ShrakeRupley()\n",
    "    sr.compute(model, level='R')\n",
    "\n",
    "    # Chain Aì˜ ì”ê¸°ë³„ SASA\n",
    "    chains = list(model.get_chains())\n",
    "    if not chains:\n",
    "        return {'error': 'No chains'}\n",
    "\n",
    "    chain_a_res = list(chains[0].get_residues())\n",
    "    n = min(len(seq), len(chain_a_res))\n",
    "\n",
    "    residue_rsa = []\n",
    "    for i in range(n):\n",
    "        res = chain_a_res[i]\n",
    "        rn = res.get_resname()\n",
    "        ma = MAX_ASA.get(rn, 200)\n",
    "        residue_rsa.append(res.sasa / ma)\n",
    "\n",
    "    core_vals = [residue_rsa[i] for i in CORE_POS if i < n]\n",
    "    surf_vals = [residue_rsa[i] for i in range(n) if i not in CORE_POS]\n",
    "\n",
    "    if not core_vals or not surf_vals:\n",
    "        return {'error': 'Not enough residues'}\n",
    "\n",
    "    core_mean = np.mean(core_vals)\n",
    "    surf_mean = np.mean(surf_vals)\n",
    "    ratio = core_mean / surf_mean if surf_mean > 0 else 999\n",
    "\n",
    "    # ê³¤ê°ë¦¬ê±´ë³„ SASA\n",
    "    type_sasa = defaultdict(list)\n",
    "    for i in range(n):\n",
    "        aa = seq[i]\n",
    "        t = AA_TO_TYPE.get(aa, '?')\n",
    "        type_sasa[t].append(residue_rsa[i])\n",
    "\n",
    "    type_means = {t: round(np.mean(v), 4) for t, v in type_sasa.items() if v}\n",
    "\n",
    "    return {\n",
    "        'core_mean': round(core_mean, 4),\n",
    "        'surface_mean': round(surf_mean, 4),\n",
    "        'burial_ratio': round(ratio, 4),\n",
    "        'burial_ok': ratio < 0.6,\n",
    "        'type_means': type_means,\n",
    "    }\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ì‹¤í–‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "burial_results = {}\n",
    "\n",
    "print('=' * 70)\n",
    "print('  ë³´ë„ˆìŠ¤: SASA Burial Ratio')\n",
    "print('=' * 70)\n",
    "print()\n",
    "\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    if gname not in pdb_files:\n",
    "        continue\n",
    "\n",
    "    g = GROUPS[gname]\n",
    "    print(f\"  â”€â”€ Group {gname}: {g['name']} â”€â”€\")\n",
    "\n",
    "    br = calc_burial_ratio_multimer(pdb_files[gname], g['seq'])\n",
    "    burial_results[gname] = br\n",
    "\n",
    "    if 'error' in br:\n",
    "        print(f\"    Error: {br['error']}\")\n",
    "    else:\n",
    "        ok = 'âœ…' if br['burial_ok'] else 'âŒ'\n",
    "        print(f\"    Core SASA (a,d): {br['core_mean']:.4f}\")\n",
    "        print(f\"    Surface SASA: {br['surface_mean']:.4f}\")\n",
    "        print(f\"    burial_ratio: {br['burial_ratio']:.4f} {ok}\")\n",
    "        print(f\"    ê³¤ê°ë¦¬ê±´ë³„ SASA: {br['type_means']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 10: ì¢…í•© ë¹„êµí‘œ + íŒì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('  UFoE Phase 5b-2: ColabFold Multimer ì¢…í•© ê²°ê³¼')\n",
    "print('=' * 80)\n",
    "print()\n",
    "\n",
    "# â”€â”€ ë¹„êµí‘œ â”€â”€\n",
    "header = f\"{'ì¸¡ì •':25s} | {'A (WT)':15s} | {'B (ê³¤ê°•í™”)':15s} | {'C (ê±´ê°•í™”)':15s}\"\n",
    "print(f\"  {header}\")\n",
    "print(f\"  {'-' * 78}\")\n",
    "\n",
    "# pLDDT\n",
    "row = f\"{'pLDDT (total)':25s}\"\n",
    "for gn in ['A', 'B', 'C']:\n",
    "    cd = confidence_data.get(gn, {})\n",
    "    v = f\"{cd.get('total', 'N/A')}\"\n",
    "    row += f\" | {v:15s}\"\n",
    "print(f\"  {row}\")\n",
    "\n",
    "# ipTM (ColabFold only)\n",
    "row = f\"{'ipTM':25s}\"\n",
    "for gn in ['A', 'B', 'C']:\n",
    "    cd = confidence_data.get(gn, {})\n",
    "    v = f\"{cd.get('iptm', 'N/A')}\"\n",
    "    row += f\" | {v:15s}\"\n",
    "print(f\"  {row}\")\n",
    "\n",
    "# Salt bridge total\n",
    "row = f\"{'Salt bridge (total)':25s}\"\n",
    "for gn in ['A', 'B', 'C']:\n",
    "    sb = salt_bridge_results.get(gn, {})\n",
    "    v = f\"{sb.get('total', 'N/A')}\"\n",
    "    row += f\" | {v:15s}\"\n",
    "print(f\"  {row}\")\n",
    "\n",
    "# Salt bridge canonical\n",
    "row = f\"{'Salt bridge (e-g\\')':25s}\"\n",
    "for gn in ['A', 'B', 'C']:\n",
    "    sb = salt_bridge_results.get(gn, {})\n",
    "    v = f\"{sb.get('canonical_count', 'N/A')}\"\n",
    "    row += f\" | {v:15s}\"\n",
    "print(f\"  {row}\")\n",
    "\n",
    "# Core packing\n",
    "for key_label, key in [('aâ†”a\\' Cb min (A)', 'a_a'), ('dâ†”d\\' Cb min (A)', 'd_d')]:\n",
    "    row = f\"{key_label:25s}\"\n",
    "    for gn in ['A', 'B', 'C']:\n",
    "        cp = core_packing_results.get(gn, {})\n",
    "        ad = cp.get('all_distances', {}).get(key) if isinstance(cp, dict) and 'error' not in cp else None\n",
    "        v = f\"{ad['min']:.1f}\" if ad else 'N/A'\n",
    "        row += f\" | {v:15s}\"\n",
    "    print(f\"  {row}\")\n",
    "\n",
    "# Crossing angle\n",
    "row = f\"{'Crossing angle (deg)':25s}\"\n",
    "for gn in ['A', 'B', 'C']:\n",
    "    ca = crossing_angle_results.get(gn, {})\n",
    "    v = f\"{ca.get('crossing_angle', 'N/A')}\" if 'error' not in ca else 'N/A'\n",
    "    row += f\" | {v:15s}\"\n",
    "print(f\"  {row}\")\n",
    "\n",
    "# Inter-helix distance\n",
    "row = f\"{'Inter-helix dist (A)':25s}\"\n",
    "for gn in ['A', 'B', 'C']:\n",
    "    ca = crossing_angle_results.get(gn, {})\n",
    "    v = f\"{ca.get('inter_helix_dist', 'N/A')}\" if 'error' not in ca else 'N/A'\n",
    "    row += f\" | {v:15s}\"\n",
    "print(f\"  {row}\")\n",
    "\n",
    "# Burial ratio\n",
    "row = f\"{'burial_ratio':25s}\"\n",
    "for gn in ['A', 'B', 'C']:\n",
    "    br = burial_results.get(gn, {})\n",
    "    v = f\"{br.get('burial_ratio', 'N/A'):.3f}\" if isinstance(br.get('burial_ratio'), (int, float)) else 'N/A'\n",
    "    row += f\" | {v:15s}\"\n",
    "print(f\"  {row}\")\n",
    "\n",
    "# â”€â”€ ESMFold ë¹„êµ â”€â”€\n",
    "print(f\"\\n  {'=' * 78}\")\n",
    "print(f\"  ESMFold pseudo-dimer vs ColabFold Multimer ë¹„êµ\")\n",
    "print(f\"  {'=' * 78}\")\n",
    "\n",
    "esmfold_ref = {\n",
    "    'A': {'plddt': 69.0, 'salt_total': 0, 'salt_eg': 0, 'dd_min': 7.24, 'angle': 24.8, 'burial': 0.529},\n",
    "    'B': {'plddt': 80.9, 'salt_total': 0, 'salt_eg': 0, 'dd_min': 4.82, 'angle': 20.2, 'burial': 0.535},\n",
    "    'C': {'plddt': 71.7, 'salt_total': 5, 'salt_eg': 1, 'dd_min': 15.53, 'angle': 11.7, 'burial': 1.345},\n",
    "}\n",
    "\n",
    "print(f\"\\n  {'ì¸¡ì •':25s} | {'ESMFold':15s} | {'ColabFold':15s} | ë³€í™”\")\n",
    "print(f\"  {'-' * 78}\")\n",
    "\n",
    "for gn in ['A', 'B', 'C']:\n",
    "    g = GROUPS[gn]\n",
    "    print(f\"\\n  == Group {gn}: {g['name']} ==\")\n",
    "    esm = esmfold_ref[gn]\n",
    "\n",
    "    cd = confidence_data.get(gn, {})\n",
    "    sb = salt_bridge_results.get(gn, {})\n",
    "    cp = core_packing_results.get(gn, {})\n",
    "    ca = crossing_angle_results.get(gn, {})\n",
    "    br = burial_results.get(gn, {})\n",
    "\n",
    "    cf_plddt = cd.get('total', 'N/A')\n",
    "    print(f\"  {'pLDDT':25s} | {esm['plddt']:15.1f} | {str(cf_plddt):15s} |\")\n",
    "\n",
    "    cf_salt = sb.get('total', 'N/A')\n",
    "    print(f\"  {'Salt bridge (total)':25s} | {esm['salt_total']:15d} | {str(cf_salt):15s} |\")\n",
    "\n",
    "    cf_eg = sb.get('canonical_count', 'N/A')\n",
    "    print(f\"  {'Salt bridge (e-g\\')':25s} | {esm['salt_eg']:15d} | {str(cf_eg):15s} |\")\n",
    "\n",
    "    dd = cp.get('all_distances', {}).get('d_d') if isinstance(cp, dict) and 'error' not in cp else None\n",
    "    cf_dd = f\"{dd['min']:.2f}\" if dd else 'N/A'\n",
    "    print(f\"  {'dâ†”d\\' Cb min':25s} | {esm['dd_min']:15.2f} | {str(cf_dd):15s} |\")\n",
    "\n",
    "    cf_angle = ca.get('crossing_angle', 'N/A') if 'error' not in ca else 'N/A'\n",
    "    print(f\"  {'Crossing angle':25s} | {esm['angle']:15.1f} | {str(cf_angle):15s} |\")\n",
    "\n",
    "    cf_burial = f\"{br['burial_ratio']:.3f}\" if isinstance(br.get('burial_ratio'), (int, float)) else 'N/A'\n",
    "    print(f\"  {'burial_ratio':25s} | {esm['burial']:15.3f} | {str(cf_burial):15s} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 11: 3ê°€ì§€ ì›ë¦¬ íŒì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print('  Phase 5b-2 íŒì •: 3ê°€ì§€ ì›ë¦¬')\n",
    "print('=' * 70)\n",
    "print()\n",
    "\n",
    "judgments = {}\n",
    "\n",
    "# â”€â”€ 1. ê³¤ ì½”ì–´ ì›ë¦¬ â”€â”€\n",
    "# Bì˜ dâ†”d' packingì´ Aë³´ë‹¤ ë°€ì°©í•´ì•¼ í•¨\n",
    "print('  [1] ê³¤ ì½”ì–´ ì›ë¦¬: Bì˜ core packing â‰¤ A?')\n",
    "print('      (ê³¤ 100% at a,d â†’ ì½”ì–´ ë” ë°€ì°©)')\n",
    "\n",
    "cp_a = core_packing_results.get('A', {})\n",
    "cp_b = core_packing_results.get('B', {})\n",
    "\n",
    "if isinstance(cp_a, dict) and 'error' not in cp_a and isinstance(cp_b, dict) and 'error' not in cp_b:\n",
    "    dd_a = cp_a.get('all_distances', {}).get('d_d', {})\n",
    "    dd_b = cp_b.get('all_distances', {}).get('d_d', {})\n",
    "\n",
    "    if dd_a and dd_b:\n",
    "        a_min = dd_a.get('min', 999)\n",
    "        b_min = dd_b.get('min', 999)\n",
    "        ok = b_min <= a_min\n",
    "        judgments['gon_core'] = ok\n",
    "        print(f'      A dâ†”d\\' min = {a_min:.2f}A')\n",
    "        print(f'      B dâ†”d\\' min = {b_min:.2f}A')\n",
    "        print(f'      â†’ {\"âœ… PASS\" if ok else \"âŒ FAIL\"}: B {\"<=\" if ok else \">\"} A')\n",
    "    else:\n",
    "        print('      â†’ âš ï¸ ë°ì´í„° ë¶€ì¡±')\n",
    "else:\n",
    "    print('      â†’ âš ï¸ ë°ì´í„° ë¶€ì¡±')\n",
    "\n",
    "print()\n",
    "\n",
    "# â”€â”€ 2. ê±´ í‘œë©´ ì›ë¦¬ â”€â”€\n",
    "# Cì—ì„œ salt bridge â‰¥ A, ë™ì‹œì— burial_ratio > A (ì½”ì–´ ë¶•ê´´)\n",
    "print('  [2] ê±´ í‘œë©´ ì›ë¦¬: C salt bridge â‰¥ A + C burial > A?')\n",
    "print('      (ê±´ 100% at e,g â†’ bridge í˜•ì„± but ì½”ì–´ ë¶•ê´´)')\n",
    "\n",
    "sb_a = salt_bridge_results.get('A', {})\n",
    "sb_c = salt_bridge_results.get('C', {})\n",
    "br_a = burial_results.get('A', {})\n",
    "br_c = burial_results.get('C', {})\n",
    "\n",
    "a_salt = sb_a.get('total', 0)\n",
    "c_salt = sb_c.get('total', 0)\n",
    "a_burial = br_a.get('burial_ratio', 999)\n",
    "c_burial = br_c.get('burial_ratio', 0)\n",
    "\n",
    "salt_ok = c_salt >= a_salt\n",
    "burial_ok = c_burial > a_burial\n",
    "both_ok = salt_ok and burial_ok\n",
    "judgments['geon_surface'] = both_ok\n",
    "\n",
    "print(f'      Salt: A={a_salt} vs C={c_salt} â†’ {\"âœ…\" if salt_ok else \"âŒ\"}')\n",
    "print(f'      Burial: A={a_burial:.3f} vs C={c_burial:.3f} â†’ {\"âœ…\" if burial_ok else \"âŒ\"}')\n",
    "print(f'      â†’ {\"âœ… PASS\" if both_ok else \"âŒ FAIL\"}')\n",
    "\n",
    "# Canonical salt bridge ìƒì„¸\n",
    "if sb_a.get('canonical'):\n",
    "    print(f'      A canonical e-g\\' bridges ({sb_a[\"canonical_count\"]}):')\n",
    "    for b in sb_a['canonical'][:5]:\n",
    "        print(f'        {b[\"aa_a\"]}{b[\"chain_a_pos\"]}({b[\"heptad_a\"]}) â€” '\n",
    "              f'{b[\"aa_b\"]}{b[\"chain_b_pos\"]}({b[\"heptad_b\"]}) {b[\"dist\"]}A')\n",
    "\n",
    "print()\n",
    "\n",
    "# â”€â”€ 3. ê· í˜• ì„¤ê³„ ì¡°ê±´ â”€â”€\n",
    "# WT crossing angleì´ 18-25 ë²”ìœ„ ë‚´\n",
    "print('  [3] ê· í˜• ì„¤ê³„ ì¡°ê±´: WT crossing angle 18-25 deg?')\n",
    "print('      (ê³¤ ì½”ì–´ + ê±´ í‘œë©´ = ìµœì  ê· í˜•)')\n",
    "\n",
    "ca_a = crossing_angle_results.get('A', {})\n",
    "if 'error' not in ca_a:\n",
    "    angle = ca_a.get('crossing_angle', 999)\n",
    "    ok = 18 <= angle <= 25\n",
    "    judgments['balance'] = ok\n",
    "    print(f'      WT crossing angle = {angle}Â°')\n",
    "    print(f'      18-25Â° range: {\"âœ… PASS\" if ok else \"âš ï¸ CHECK\"}')\n",
    "    \n",
    "    # B, Cë„ ë¹„êµ\n",
    "    ca_b = crossing_angle_results.get('B', {})\n",
    "    ca_c = crossing_angle_results.get('C', {})\n",
    "    if 'error' not in ca_b:\n",
    "        print(f'      B crossing angle = {ca_b.get(\"crossing_angle\", \"N/A\")}Â°')\n",
    "    if 'error' not in ca_c:\n",
    "        print(f'      C crossing angle = {ca_c.get(\"crossing_angle\", \"N/A\")}Â°')\n",
    "else:\n",
    "    print(f'      â†’ âš ï¸ Error: {ca_a.get(\"error\")}')\n",
    "\n",
    "# â”€â”€ ìµœì¢… íŒì • â”€â”€\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"  ìµœì¢… íŒì •\")\n",
    "print(f\"{'=' * 70}\")\n",
    "print()\n",
    "\n",
    "pass_count = sum(1 for v in judgments.values() if v)\n",
    "total_count = len(judgments)\n",
    "\n",
    "for name, ok in judgments.items():\n",
    "    label = {\n",
    "        'gon_core': 'ê³¤ ì½”ì–´ ì›ë¦¬',\n",
    "        'geon_surface': 'ê±´ í‘œë©´ ì›ë¦¬',\n",
    "        'balance': 'ê· í˜• ì„¤ê³„ ì¡°ê±´',\n",
    "    }.get(name, name)\n",
    "    print(f\"  {label}: {'âœ… PASS' if ok else 'âŒ FAIL'}\")\n",
    "\n",
    "print(f\"\\n  ê²°ê³¼: {pass_count}/{total_count} PASS\")\n",
    "\n",
    "if pass_count == total_count:\n",
    "    print(\"\\n  ğŸ‰ ColabFold Multimerë¡œ ê³¤ê°ë¦¬ê±´ 3ì›ë¦¬ ëª¨ë‘ ê²€ì¦ ì„±ê³µ!\")\n",
    "else:\n",
    "    print(f\"\\n  âš ï¸ {total_count - pass_count}ê°œ ì›ë¦¬ ì¶”ê°€ ê²€ì¦ í•„ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 12: ê²°ê³¼ ì €ì¥ + ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ê²°ê³¼ JSON ì €ì¥\n",
    "final_results = {\n",
    "    'experiment': 'UFoE Phase 5b-2 ColabFold Multimer',\n",
    "    'date': '2026-02-13',\n",
    "    'groups': {},\n",
    "    'judgments': judgments,\n",
    "}\n",
    "\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    g = GROUPS[gname]\n",
    "    final_results['groups'][gname] = {\n",
    "        'name': g['name'],\n",
    "        'seq': g['seq'],\n",
    "        'desc': g['desc'],\n",
    "        'confidence': confidence_data.get(gname, {}),\n",
    "        'salt_bridges': salt_bridge_results.get(gname, {}),\n",
    "        'core_packing': core_packing_results.get(gname, {}),\n",
    "        'crossing_angle': crossing_angle_results.get(gname, {}),\n",
    "        'burial': burial_results.get(gname, {}),\n",
    "    }\n",
    "\n",
    "# ESMFold ë¹„êµ ë°ì´í„°\n",
    "final_results['esmfold_comparison'] = {\n",
    "    'A': {'plddt': 69.0, 'salt_total': 0, 'salt_eg': 0, 'dd_min': 7.24, 'angle': 24.8, 'burial': 0.529},\n",
    "    'B': {'plddt': 80.9, 'salt_total': 0, 'salt_eg': 0, 'dd_min': 4.82, 'angle': 20.2, 'burial': 0.535},\n",
    "    'C': {'plddt': 71.7, 'salt_total': 5, 'salt_eg': 1, 'dd_min': 15.53, 'angle': 11.7, 'burial': 1.345},\n",
    "}\n",
    "\n",
    "# ì €ì¥\n",
    "result_json_path = OUTPUT_DIR / 'phase5b2_colabfold_results.json'\n",
    "with open(result_json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_results, f, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "print(f\"  ê²°ê³¼ ì €ì¥: {result_json_path}\")\n",
    "\n",
    "# Google Colab ë‹¤ìš´ë¡œë“œ\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(str(result_json_path))\n",
    "    print(\"\\n  ğŸ“¥ JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘\")\n",
    "\n",
    "    # PDB íŒŒì¼ë„ ë‹¤ìš´ë¡œë“œ\n",
    "    for gname in ['A', 'B', 'C']:\n",
    "        if gname in pdb_files and os.path.exists(pdb_files[gname]):\n",
    "            files.download(pdb_files[gname])\n",
    "            print(f\"  ğŸ“¥ Group {gname} PDB ë‹¤ìš´ë¡œë“œ\")\n",
    "except ImportError:\n",
    "    print(\"\\n  (Google Colab ì•„ë‹˜ â€” ìˆ˜ë™ìœ¼ë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”)\")\n",
    "    print(f\"  JSON: {result_json_path}\")\n",
    "    for gname in ['A', 'B', 'C']:\n",
    "        if gname in pdb_files:\n",
    "            print(f\"  PDB {gname}: {pdb_files[gname]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 13: êµ¬ì¡° ì‹œê°í™” (Optional)\n",
    "\n",
    "py3Dmolë¡œ 3D êµ¬ì¡° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import py3Dmol\n",
    "except ImportError:\n",
    "    os.system('pip install -q py3Dmol')\n",
    "    import py3Dmol\n",
    "\n",
    "def visualize_dimer(pdb_path, title=''):\n",
    "    \"\"\"ì½”ì¼ë“œ-ì½”ì¼ ë‹¤ì´ë¨¸ 3D ì‹œê°í™”.\"\"\"\n",
    "    with open(pdb_path) as f:\n",
    "        pdb_text = f.read()\n",
    "\n",
    "    view = py3Dmol.view(width=600, height=400)\n",
    "    view.addModel(pdb_text, 'pdb')\n",
    "\n",
    "    # Chain A: cyan, Chain B: orange\n",
    "    view.setStyle({'chain': 'A'}, {'cartoon': {'color': 'cyan'}})\n",
    "    view.setStyle({'chain': 'B'}, {'cartoon': {'color': 'orange'}})\n",
    "\n",
    "    # a,d core residues: spheres\n",
    "    for pos in CORE_POS:\n",
    "        resi = pos + 1  # 1-indexed\n",
    "        view.addStyle({'chain': 'A', 'resi': resi}, {'stick': {'color': 'blue'}})\n",
    "        view.addStyle({'chain': 'B', 'resi': resi}, {'stick': {'color': 'red'}})\n",
    "\n",
    "    # e,g salt bridge positions: thin sticks\n",
    "    for pos in sorted(E_POS + G_POS):\n",
    "        resi = pos + 1\n",
    "        view.addStyle({'chain': 'A', 'resi': resi}, {'stick': {'color': 'green', 'radius': 0.1}})\n",
    "        view.addStyle({'chain': 'B', 'resi': resi}, {'stick': {'color': 'yellow', 'radius': 0.1}})\n",
    "\n",
    "    view.zoomTo()\n",
    "    if title:\n",
    "        print(f\"\\n  {title}\")\n",
    "    return view\n",
    "\n",
    "\n",
    "# ê° ê·¸ë£¹ ì‹œê°í™”\n",
    "for gname in ['A', 'B', 'C']:\n",
    "    if gname in pdb_files and os.path.exists(pdb_files[gname]):\n",
    "        g = GROUPS[gname]\n",
    "        view = visualize_dimer(\n",
    "            pdb_files[gname],\n",
    "            f\"Group {gname}: {g['name']} ({g['desc']})\"\n",
    "        )\n",
    "        view.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì‹¤í–‰ ê°€ì´ë“œ\n",
    "\n",
    "### Google Colab ì‹¤í–‰ ìˆœì„œ:\n",
    "1. **Cell 1**: ColabFold ì„¤ì¹˜ (~5ë¶„)\n",
    "2. **Cell 2**: ì„¤ì • + ì„œì—´ í™•ì¸\n",
    "3. **Cell 3**: ColabFold Multimer ì˜ˆì¸¡ (~30-45ë¶„)\n",
    "4. **Cell 4**: PDB íŒŒì¼ íƒìƒ‰\n",
    "5. **Cell 5-9**: ë¶„ì„ ì‹¤í–‰ (ìˆœì„œëŒ€ë¡œ)\n",
    "6. **Cell 10**: ì¢…í•© ë¹„êµí‘œ\n",
    "7. **Cell 11**: 3ì›ë¦¬ íŒì •\n",
    "8. **Cell 12**: ê²°ê³¼ ì €ì¥ + ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "### ì£¼ì˜ì‚¬í•­:\n",
    "- GPU ëŸ°íƒ€ì„ í•„ìˆ˜ (ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > T4 GPU)\n",
    "- ColabFold ì„¤ì¹˜ í›„ ëŸ°íƒ€ì„ ì¬ì‹œì‘ í•„ìš”í•  ìˆ˜ ìˆìŒ\n",
    "- 3 ê·¸ë£¹ Ã— 5 ëª¨ë¸ = 15 ì˜ˆì¸¡ â†’ ~30-45ë¶„ ì†Œìš”\n",
    "- ë¬´ë£Œ Colabì€ ì‹œê°„ ì œí•œì´ ìˆìœ¼ë¯€ë¡œ, ê°œë³„ ê·¸ë£¹ ì‹¤í–‰ ì˜µì…˜ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "### ESMFold ê¸°ì¤€ì„  (Phase 5b-2 ê²°ê³¼):\n",
    "\n",
    "| ì¸¡ì • | A (WT) | B (ê³¤ê°•í™”) | C (ê±´ê°•í™”) |\n",
    "|------|--------|-----------|----------|\n",
    "| pLDDT | 69.0 | **80.9** | 71.7 |\n",
    "| Salt bridge (e-g') | 0 | 0 | 1 |\n",
    "| dâ†”d' Cb min | 7.24A | **4.82A** | 15.53A |\n",
    "| Crossing angle | **24.8 deg** | **20.2 deg** | 11.7 deg |\n",
    "| burial_ratio | 0.529 | 0.535 | 1.345 |\n",
    "\n",
    "### ì„±ê³µ ê¸°ì¤€:\n",
    "- ê³¤ ì½”ì–´ ì›ë¦¬: B dâ†”d' â‰¤ A dâ†”d' âœ…\n",
    "- ê±´ í‘œë©´ ì›ë¦¬: C salt â‰¥ A + C burial > A âœ…  \n",
    "- ê· í˜• ì„¤ê³„: WT angle 18-25 deg âœ…"
   ]
  }
 ]
}