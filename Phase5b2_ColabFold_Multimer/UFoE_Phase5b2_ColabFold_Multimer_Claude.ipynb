{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UFoE Phase 5b-2: ColabFold Multimer ê²€ì¦\n",
        "## ê³¤ ì½”ì–´ / ê±´ í‘œë©´ / ê· í˜• ì„¤ê³„ â€” ìµœì¢… ê²€ì¦\n",
        "\n",
        "### í™•ì¸ ì‚¬í•­ 3ê°€ì§€:\n",
        "1. **Inter-chain salt bridge** (eâ†”g') ì •ë ¬ ì—¬ë¶€\n",
        "2. **a,d registry alignment** ë³´ì¡´ ì—¬ë¶€  \n",
        "3. **Oligomeric state** ìœ ì§€ ì—¬ë¶€ (C ê·¸ë£¹ì´ dimer ìœ ì§€í•˜ëŠ”ì§€)\n",
        "\n",
        "### ì‹¤í—˜ ê·¸ë£¹:\n",
        "- **A (WT)**: RMKQLEDKVEELLSKNYHLENEVARLKKLVGER\n",
        "- **B (ê³¤ê°•í™”)**: LMKQLEDIVEELLSLNYHLEINEVALKKLLGEL\n",
        "- **C (ê±´ê°•í™”)**: REKSLEDKVEELLSKEYKLENEVERKKLEGEK\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: ColabFold ì„¤ì¹˜ ë° ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ColabFold ì„¤ì¹˜ (Google Colabì—ì„œ ì‹¤í–‰)\n",
        "!pip install -q colabfold[alphafold]@git+https://github.com/sokrypton/ColabFold\n",
        "!pip install -q biopython matplotlib numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: í™•ì • ì„œì—´ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# === í™•ì • ì„œì—´ ===\n",
        "SEQUENCES = {\n",
        "    'A_WT': 'RMKQLEDKVEELLSKNYHLENEVARLKKLVGER',\n",
        "    'B_GON': 'LMKQLEDIVEELLSLNYHLEINEVALKKLLGEL',\n",
        "    'C_GEON': 'REKSLEDKVEELLSKEYKLENEVERKKLEGEK'\n",
        "}\n",
        "\n",
        "# === ê³¤ê°ë¦¬ê±´ ë§¤í•‘ ===\n",
        "GGRL_MAP = {\n",
        "    'A':'gon','L':'gon','V':'gon','I':'gon','F':'gon','M':'gon','W':'gon',\n",
        "    'G':'gam','C':'gam','P':'gam',\n",
        "    'S':'ri','T':'ri','N':'ri','Q':'ri','H':'ri','Y':'ri',\n",
        "    'E':'geon','D':'geon','K':'geon','R':'geon'\n",
        "}\n",
        "\n",
        "# === Heptad Registry ===\n",
        "def get_heptad_registry(seq_length, start_position='d'):\n",
        "    heptad = ['d', 'e', 'f', 'g', 'a', 'b', 'c']\n",
        "    start_offset = heptad.index(start_position)\n",
        "    return {i: heptad[(i + start_offset) % 7] for i in range(seq_length)}\n",
        "\n",
        "def get_positions_by_role(registry):\n",
        "    roles = {'a': [], 'd': [], 'e': [], 'g': [], 'bcf': []}\n",
        "    for idx, letter in registry.items():\n",
        "        if letter in ('a', 'd', 'e', 'g'):\n",
        "            roles[letter].append(idx)\n",
        "        else:\n",
        "            roles['bcf'].append(idx)\n",
        "    return roles\n",
        "\n",
        "# ì„œì—´ ê²€ì¦\n",
        "for name, seq in SEQUENCES.items():\n",
        "    reg = get_heptad_registry(len(seq))\n",
        "    pos = get_positions_by_role(reg)\n",
        "    ggrl = [GGRL_MAP[aa] for aa in seq]\n",
        "    n = len(ggrl)\n",
        "    ratio = {t: round(ggrl.count(t)/n*100, 1) for t in ['gon','gam','ri','geon']}\n",
        "    print(f'{name} ({len(seq)}aa): gon={ratio[\"gon\"]}% gam={ratio[\"gam\"]}% ri={ratio[\"ri\"]}% geon={ratio[\"geon\"]}%')\n",
        "    print(f'  a positions: {[seq[i] for i in pos[\"a\"]]}')\n",
        "    print(f'  d positions: {[seq[i] for i in pos[\"d\"]]}')\n",
        "    print(f'  e positions: {[seq[i] for i in pos[\"e\"]]}')\n",
        "    print(f'  g positions: {[seq[i] for i in pos[\"g\"]]}')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: FASTA íŒŒì¼ ìƒì„± ë° ColabFold ì‹¤í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FASTA íŒŒì¼ ìƒì„± (ColabFold Multimerìš©: ':' ë¡œ ì²´ì¸ êµ¬ë¶„)\n",
        "os.makedirs('gcn4_colabfold', exist_ok=True)\n",
        "\n",
        "for name, seq in SEQUENCES.items():\n",
        "    fasta_path = f'gcn4_colabfold/{name}.fasta'\n",
        "    # Homodimer: ë™ì¼ ì„œì—´ 2ê°œ\n",
        "    with open(fasta_path, 'w') as f:\n",
        "        f.write(f'>{name}\\n')\n",
        "        f.write(f'{seq}:{seq}\\n')  # ':' = chain separator\n",
        "    print(f'Created: {fasta_path}')\n",
        "    print(f'  Content: {seq}:{seq}')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === ColabFold Multimer ì‹¤í–‰ ===\n",
        "# ê° ê·¸ë£¹ë³„ë¡œ ì‹¤í–‰ (ì‹œê°„: ê·¸ë£¹ë‹¹ ~5-10ë¶„)\n",
        "\n",
        "for name in SEQUENCES.keys():\n",
        "    fasta = f'gcn4_colabfold/{name}.fasta'\n",
        "    outdir = f'gcn4_colabfold/output_{name}'\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    \n",
        "    print(f'\\n=== Running ColabFold for {name} ===')\n",
        "    !colabfold_batch {fasta} {outdir} \\\n",
        "        --num-models 5 \\\n",
        "        --num-recycles 3 \\\n",
        "        --model-type alphafold2_multimer_v3 \\\n",
        "        --templates \\\n",
        "        --amber\n",
        "    \n",
        "    print(f'Done: {name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: PDB íŒŒì¼ ë¡œë“œ\n",
        "\n",
        "ColabFoldê°€ ì™„ë£Œë˜ë©´ rank_001 PDBë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "from Bio.PDB import PDBParser\n",
        "\n",
        "def find_best_pdb(output_dir):\n",
        "    \"\"\"rank_001 ë˜ëŠ” ìµœê³  pLDDT PDB ì°¾ê¸°\"\"\"\n",
        "    pdbs = glob.glob(os.path.join(output_dir, '*rank_001*.pdb'))\n",
        "    if not pdbs:\n",
        "        pdbs = glob.glob(os.path.join(output_dir, '*.pdb'))\n",
        "    if not pdbs:\n",
        "        # relaxed ë²„ì „ í™•ì¸\n",
        "        pdbs = glob.glob(os.path.join(output_dir, '*relaxed*.pdb'))\n",
        "    return pdbs[0] if pdbs else None\n",
        "\n",
        "pdb_files = {}\n",
        "for name in SEQUENCES.keys():\n",
        "    outdir = f'gcn4_colabfold/output_{name}'\n",
        "    pdb = find_best_pdb(outdir)\n",
        "    if pdb:\n",
        "        pdb_files[name] = pdb\n",
        "        print(f'{name}: {pdb}')\n",
        "    else:\n",
        "        print(f'{name}: PDB not found! Check output directory.')\n",
        "\n",
        "# ì²´ì¸ ìˆ˜ í™•ì¸\n",
        "parser = PDBParser(QUIET=True)\n",
        "for name, pdb_path in pdb_files.items():\n",
        "    structure = parser.get_structure(name, pdb_path)\n",
        "    chains = list(structure[0].get_chains())\n",
        "    print(f'{name}: {len(chains)} chains ({[c.id for c in chains]})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: ë¶„ì„ í•¨ìˆ˜ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ë¶„ì„ 1: Inter-chain Salt Bridge (eâ†”g' registry í•„í„°)\n",
        "# ============================================================\n",
        "\n",
        "def detect_salt_bridges(pdb_file, sequence, cutoff=4.0):\n",
        "    \"\"\"\n",
        "    Inter-chain salt bridge ê²€ì¶œ.\n",
        "    ì •ê·œ(eâ†”g') vs ë¹„ì •ê·œ ë¶„ë¦¬.\n",
        "    \"\"\"\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('dimer', pdb_file)\n",
        "    chains = list(structure[0].get_chains())\n",
        "    \n",
        "    if len(chains) < 2:\n",
        "        print('ERROR: Need 2 chains for dimer analysis')\n",
        "        return None\n",
        "    \n",
        "    registry = get_heptad_registry(len(sequence))\n",
        "    positions = get_positions_by_role(registry)\n",
        "    e_set = set(positions['e'])\n",
        "    g_set = set(positions['g'])\n",
        "    \n",
        "    neg_atoms = {'GLU': ['OE1', 'OE2'], 'ASP': ['OD1', 'OD2']}\n",
        "    pos_atoms = {'LYS': ['NZ'], 'ARG': ['NH1', 'NH2']}\n",
        "    \n",
        "    regular = []\n",
        "    irregular = []\n",
        "    \n",
        "    res_a = list(chains[0].get_residues())\n",
        "    res_b = list(chains[1].get_residues())\n",
        "    \n",
        "    for i, ra in enumerate(res_a):\n",
        "        rn_a = ra.get_resname()\n",
        "        is_neg_a = rn_a in neg_atoms\n",
        "        is_pos_a = rn_a in pos_atoms\n",
        "        if not (is_neg_a or is_pos_a):\n",
        "            continue\n",
        "        \n",
        "        for j, rb in enumerate(res_b):\n",
        "            rn_b = rb.get_resname()\n",
        "            is_neg_b = rn_b in neg_atoms\n",
        "            is_pos_b = rn_b in pos_atoms\n",
        "            if not (is_neg_b or is_pos_b):\n",
        "                continue\n",
        "            \n",
        "            # ë°˜ëŒ€ ì „í•˜ë§Œ\n",
        "            if not ((is_neg_a and is_pos_b) or (is_pos_a and is_neg_b)):\n",
        "                continue\n",
        "            \n",
        "            # ì›ì ìˆ˜ì¤€ ìµœì†Œ ê±°ë¦¬\n",
        "            a_names = neg_atoms.get(rn_a, []) + pos_atoms.get(rn_a, [])\n",
        "            b_names = neg_atoms.get(rn_b, []) + pos_atoms.get(rn_b, [])\n",
        "            \n",
        "            min_dist = 999\n",
        "            for an in a_names:\n",
        "                for bn in b_names:\n",
        "                    if an in ra and bn in rb:\n",
        "                        d = ra[an] - rb[bn]\n",
        "                        if d < min_dist:\n",
        "                            min_dist = d\n",
        "            \n",
        "            if min_dist < cutoff:\n",
        "                info = {\n",
        "                    'chain_a_res': f'{rn_a}{i+1}',\n",
        "                    'chain_b_res': f'{rn_b}{j+1}',\n",
        "                    'distance': round(min_dist, 2),\n",
        "                    'heptad_a': registry.get(i, '?'),\n",
        "                    'heptad_b': registry.get(j, '?')\n",
        "                }\n",
        "                \n",
        "                is_eg = (i in e_set and j in g_set)\n",
        "                is_ge = (i in g_set and j in e_set)\n",
        "                \n",
        "                if is_eg or is_ge:\n",
        "                    info['type'] = 'REGULAR (eâ†”g\\')'\n",
        "                    regular.append(info)\n",
        "                else:\n",
        "                    info['type'] = 'irregular'\n",
        "                    irregular.append(info)\n",
        "    \n",
        "    return {\n",
        "        'regular': regular,\n",
        "        'irregular': irregular,\n",
        "        'regular_count': len(regular),\n",
        "        'irregular_count': len(irregular),\n",
        "        'total': len(regular) + len(irregular)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ë¶„ì„ 2: a,d Core Packing (CÎ²-CÎ² distance)\n",
        "# ============================================================\n",
        "\n",
        "def analyze_core_packing(pdb_file, sequence):\n",
        "    \"\"\"\n",
        "    Chain Aì˜ a,d â†” Chain Bì˜ a,d ìœ„ì¹˜ CÎ²-CÎ² ê±°ë¦¬.\n",
        "    \n",
        "    ì •ìƒ ë²”ìœ„:\n",
        "    - dâ†”d': 5-8Ã… (knobs-into-holes)\n",
        "    - aâ†”a': 6-8Ã…\n",
        "    \"\"\"\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('dimer', pdb_file)\n",
        "    chains = list(structure[0].get_chains())\n",
        "    \n",
        "    if len(chains) < 2:\n",
        "        return None\n",
        "    \n",
        "    registry = get_heptad_registry(len(sequence))\n",
        "    positions = get_positions_by_role(registry)\n",
        "    \n",
        "    def get_cb(residue):\n",
        "        if 'CB' in residue:\n",
        "            return residue['CB'].get_vector().get_array()\n",
        "        elif 'CA' in residue:\n",
        "            return residue['CA'].get_vector().get_array()\n",
        "        return None\n",
        "    \n",
        "    res_a = list(chains[0].get_residues())\n",
        "    res_b = list(chains[1].get_residues())\n",
        "    \n",
        "    distances = {'a_a': [], 'd_d': [], 'a_d': []}\n",
        "    details = {'a_a': [], 'd_d': [], 'a_d': []}\n",
        "    \n",
        "    # dâ†”d' (ê°™ì€ heptad ìœ„ì¹˜ë¼ë¦¬ â€” ê°€ì¥ ì¤‘ìš”)\n",
        "    for pos in positions['d']:\n",
        "        if pos < len(res_a) and pos < len(res_b):\n",
        "            cb_a = get_cb(res_a[pos])\n",
        "            cb_b = get_cb(res_b[pos])\n",
        "            if cb_a is not None and cb_b is not None:\n",
        "                dist = np.linalg.norm(cb_a - cb_b)\n",
        "                distances['d_d'].append(round(dist, 2))\n",
        "                details['d_d'].append({\n",
        "                    'pos': pos+1,\n",
        "                    'aa_a': sequence[pos],\n",
        "                    'aa_b': sequence[pos],\n",
        "                    'dist': round(dist, 2)\n",
        "                })\n",
        "    \n",
        "    # aâ†”a'\n",
        "    for pos in positions['a']:\n",
        "        if pos < len(res_a) and pos < len(res_b):\n",
        "            cb_a = get_cb(res_a[pos])\n",
        "            cb_b = get_cb(res_b[pos])\n",
        "            if cb_a is not None and cb_b is not None:\n",
        "                dist = np.linalg.norm(cb_a - cb_b)\n",
        "                distances['a_a'].append(round(dist, 2))\n",
        "                details['a_a'].append({\n",
        "                    'pos': pos+1,\n",
        "                    'aa_a': sequence[pos],\n",
        "                    'aa_b': sequence[pos],\n",
        "                    'dist': round(dist, 2)\n",
        "                })\n",
        "    \n",
        "    # aâ†”d' (knobs-into-holes)\n",
        "    for pos_a in positions['a']:\n",
        "        for pos_d in positions['d']:\n",
        "            if pos_a < len(res_a) and pos_d < len(res_b):\n",
        "                cb_a = get_cb(res_a[pos_a])\n",
        "                cb_b = get_cb(res_b[pos_d])\n",
        "                if cb_a is not None and cb_b is not None:\n",
        "                    dist = np.linalg.norm(cb_a - cb_b)\n",
        "                    if dist < 12.0:\n",
        "                        distances['a_d'].append(round(dist, 2))\n",
        "    \n",
        "    result = {}\n",
        "    for key in distances:\n",
        "        if distances[key]:\n",
        "            result[key] = {\n",
        "                'mean': round(np.mean(distances[key]), 2),\n",
        "                'std': round(np.std(distances[key]), 2),\n",
        "                'min': round(min(distances[key]), 2),\n",
        "                'max': round(max(distances[key]), 2),\n",
        "                'values': distances[key],\n",
        "                'details': details.get(key, [])\n",
        "            }\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ë¶„ì„ 3: Crossing Angle (DSSP helix-only PCA)\n",
        "# ============================================================\n",
        "\n",
        "def calculate_crossing_angle(pdb_file):\n",
        "    \"\"\"\n",
        "    DSSP helix ì”ê¸°ë§Œìœ¼ë¡œ PCA â†’ helix ì¶• â†’ êµì°¨ê°.\n",
        "    DSSP ì‹¤íŒ¨ ì‹œ ì „ì²´ CA fallback.\n",
        "    \n",
        "    ì½”ì¼ë“œ-ì½”ì¼ ì •ìƒ ë²”ìœ„: 18-25Â°\n",
        "    \"\"\"\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('dimer', pdb_file)\n",
        "    model = structure[0]\n",
        "    chains = list(model.get_chains())\n",
        "    \n",
        "    if len(chains) < 2:\n",
        "        return None\n",
        "    \n",
        "    # DSSP ì‹œë„\n",
        "    helix_res = {0: set(), 1: set()}\n",
        "    dssp_used = False\n",
        "    try:\n",
        "        from Bio.PDB.DSSP import DSSP\n",
        "        dssp = DSSP(model, pdb_file, dssp='mkdssp')\n",
        "        for key, value in dssp:\n",
        "            chain_id = key[0]\n",
        "            res_id = key[1][1]\n",
        "            ss = value[2]\n",
        "            if ss == 'H':\n",
        "                ci = 0 if chain_id == chains[0].id else 1\n",
        "                helix_res[ci].add(res_id)\n",
        "        dssp_used = True\n",
        "    except:\n",
        "        for ci, chain in enumerate(chains):\n",
        "            for res in chain:\n",
        "                helix_res[ci].add(res.get_id()[1])\n",
        "    \n",
        "    def get_axis(chain, h_set):\n",
        "        ca = []\n",
        "        for res in chain:\n",
        "            if res.get_id()[1] in h_set and 'CA' in res:\n",
        "                ca.append(res['CA'].get_vector().get_array())\n",
        "        if len(ca) < 5:\n",
        "            return None, None\n",
        "        ca = np.array(ca)\n",
        "        center = ca.mean(axis=0)\n",
        "        centered = ca - center\n",
        "        cov = np.cov(centered.T)\n",
        "        eigvals, eigvecs = np.linalg.eigh(cov)\n",
        "        return eigvecs[:, np.argmax(eigvals)], center\n",
        "    \n",
        "    ax_a, c_a = get_axis(chains[0], helix_res[0])\n",
        "    ax_b, c_b = get_axis(chains[1], helix_res[1])\n",
        "    \n",
        "    if ax_a is None or ax_b is None:\n",
        "        return None\n",
        "    \n",
        "    dot = np.dot(ax_a, ax_b)\n",
        "    angle = np.degrees(np.arccos(min(1.0, abs(dot))))\n",
        "    \n",
        "    return {\n",
        "        'crossing_angle': round(angle, 1),\n",
        "        'orientation': 'parallel' if dot > 0 else 'antiparallel',\n",
        "        'helix_A': len(helix_res[0]),\n",
        "        'helix_B': len(helix_res[1]),\n",
        "        'dssp_used': dssp_used\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ë¶„ì„ 4: Oligomeric State í™•ì¸\n",
        "# ============================================================\n",
        "\n",
        "def check_oligomeric_state(pdb_file):\n",
        "    \"\"\"\n",
        "    ë‘ ì²´ì¸ì´ ì‹¤ì œë¡œ dimerë¥¼ í˜•ì„±í•˜ëŠ”ì§€ í™•ì¸.\n",
        "    - ì²´ì¸ ê°„ ìµœì†Œ ê±°ë¦¬\n",
        "    - ì ‘ì´‰ ì”ê¸° ìˆ˜\n",
        "    - ì¸í„°í˜ì´ìŠ¤ ë©´ì  ì¶”ì •\n",
        "    \n",
        "    C ê·¸ë£¹ í•µì‹¬: dimer ìœ ì§€ vs monomer-like collapse\n",
        "    \"\"\"\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('dimer', pdb_file)\n",
        "    chains = list(structure[0].get_chains())\n",
        "    \n",
        "    if len(chains) < 2:\n",
        "        return {'state': 'MONOMER', 'chains': 1}\n",
        "    \n",
        "    # ì²´ì¸ ê°„ CA-CA ê±°ë¦¬\n",
        "    ca_a = [r['CA'].get_vector().get_array() for r in chains[0] if 'CA' in r]\n",
        "    ca_b = [r['CA'].get_vector().get_array() for r in chains[1] if 'CA' in r]\n",
        "    \n",
        "    ca_a = np.array(ca_a)\n",
        "    ca_b = np.array(ca_b)\n",
        "    \n",
        "    # ëª¨ë“  ìŒ ê±°ë¦¬\n",
        "    from scipy.spatial.distance import cdist\n",
        "    dist_matrix = cdist(ca_a, ca_b)\n",
        "    \n",
        "    min_dist = dist_matrix.min()\n",
        "    contact_count = (dist_matrix < 8.0).sum()  # 8Ã… ì´ë‚´ ì ‘ì´‰\n",
        "    close_count = (dist_matrix < 5.0).sum()    # 5Ã… ì´ë‚´ ë°€ì ‘\n",
        "    \n",
        "    # ì²´ì¸ ì¤‘ì‹¬ ê°„ ê±°ë¦¬\n",
        "    center_a = ca_a.mean(axis=0)\n",
        "    center_b = ca_b.mean(axis=0)\n",
        "    center_dist = np.linalg.norm(center_a - center_b)\n",
        "    \n",
        "    # íŒì •\n",
        "    if min_dist > 12.0:\n",
        "        state = 'SEPARATED (no contact)'\n",
        "    elif contact_count < 5:\n",
        "        state = 'WEAK DIMER'\n",
        "    elif close_count > 10:\n",
        "        state = 'TIGHT DIMER'\n",
        "    else:\n",
        "        state = 'DIMER'\n",
        "    \n",
        "    return {\n",
        "        'state': state,\n",
        "        'chains': len(chains),\n",
        "        'min_distance': round(min_dist, 2),\n",
        "        'contacts_8A': int(contact_count),\n",
        "        'contacts_5A': int(close_count),\n",
        "        'center_distance': round(center_dist, 2)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ë¶„ì„ 5: SASA (ê³¤ ë§¤ëª° ìµœì¢… í™•ì¸)\n",
        "# ============================================================\n",
        "\n",
        "def analyze_sasa(pdb_file, sequence):\n",
        "    \"\"\"\n",
        "    Dimerì—ì„œ ê³¤ê°ë¦¬ê±´ íƒ€ì…ë³„ ìƒëŒ€ SASA.\n",
        "    Phase 5aì—ì„œ ë¶ˆê°€ëŠ¥í–ˆë˜ ê³¤ ë§¤ëª° ê²€ì¦.\n",
        "    \"\"\"\n",
        "    from Bio.PDB.SASA import ShrakeRupley\n",
        "    \n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('dimer', pdb_file)\n",
        "    sr = ShrakeRupley()\n",
        "    sr.compute(structure[0], level='R')\n",
        "    \n",
        "    max_sasa = {\n",
        "        'A':129,'R':274,'N':195,'D':193,'C':167,\n",
        "        'E':223,'Q':225,'G':104,'H':224,'I':197,\n",
        "        'L':201,'K':236,'M':224,'F':240,'P':159,\n",
        "        'S':155,'T':172,'W':285,'Y':263,'V':174\n",
        "    }\n",
        "    \n",
        "    sasa_by_type = {'gon':[], 'gam':[], 'ri':[], 'geon':[]}\n",
        "    seq_combined = sequence + sequence  # dimer\n",
        "    \n",
        "    for i, res in enumerate(structure[0].get_residues()):\n",
        "        if i < len(seq_combined):\n",
        "            aa = seq_combined[i]\n",
        "            ggrl = GGRL_MAP.get(aa)\n",
        "            if ggrl:\n",
        "                rel = res.sasa / max_sasa.get(aa, 200)\n",
        "                sasa_by_type[ggrl].append(rel)\n",
        "    \n",
        "    result = {}\n",
        "    for t in ['gon', 'gam', 'ri', 'geon']:\n",
        "        if sasa_by_type[t]:\n",
        "            result[t] = {\n",
        "                'mean': round(np.mean(sasa_by_type[t]), 3),\n",
        "                'std': round(np.std(sasa_by_type[t]), 3),\n",
        "                'n': len(sasa_by_type[t])\n",
        "            }\n",
        "    \n",
        "    # ë‚˜ì´í…Œ ìˆœì„œ íŒì •: ê³¤ < ë¦¬ < ê±´\n",
        "    if 'gon' in result and 'geon' in result:\n",
        "        result['naitae_order'] = result['gon']['mean'] < result.get('ri', {}).get('mean', 999) < result['geon']['mean']\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: ì¢…í•© ë¶„ì„ ì‹¤í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ì¢…í•© ì‹¤í–‰\n",
        "# ============================================================\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for name in SEQUENCES.keys():\n",
        "    if name not in pdb_files:\n",
        "        print(f'\\nâš ï¸ {name}: PDB not found, skipping')\n",
        "        continue\n",
        "    \n",
        "    pdb = pdb_files[name]\n",
        "    seq = SEQUENCES[name]\n",
        "    \n",
        "    print(f'\\n{\"=\"*60}')\n",
        "    print(f'=== {name} ===')\n",
        "    print(f'{\"=\"*60}')\n",
        "    \n",
        "    # 1. Oligomeric State\n",
        "    oligo = check_oligomeric_state(pdb)\n",
        "    print(f'\\n[Oligomeric State]')\n",
        "    print(f'  State: {oligo[\"state\"]}')\n",
        "    print(f'  Min distance: {oligo[\"min_distance\"]}Ã…')\n",
        "    print(f'  Contacts (8Ã…): {oligo[\"contacts_8A\"]}')\n",
        "    print(f'  Center distance: {oligo[\"center_distance\"]}Ã…')\n",
        "    \n",
        "    # 2. Salt Bridge\n",
        "    sb = detect_salt_bridges(pdb, seq)\n",
        "    print(f'\\n[Salt Bridges]')\n",
        "    if sb:\n",
        "        print(f'  Regular (eâ†”g\\'): {sb[\"regular_count\"]}')\n",
        "        for b in sb['regular']:\n",
        "            print(f'    {b[\"chain_a_res\"]}({b[\"heptad_a\"]}) â†” {b[\"chain_b_res\"]}({b[\"heptad_b\"]}) = {b[\"distance\"]}Ã…')\n",
        "        print(f'  Irregular: {sb[\"irregular_count\"]}')\n",
        "        print(f'  Total: {sb[\"total\"]}')\n",
        "    \n",
        "    # 3. Core Packing\n",
        "    cp = analyze_core_packing(pdb, seq)\n",
        "    print(f'\\n[Core Packing (CÎ²-CÎ²)]')\n",
        "    if cp:\n",
        "        for key in ['d_d', 'a_a', 'a_d']:\n",
        "            if key in cp:\n",
        "                print(f'  {key}: mean={cp[key][\"mean\"]}Ã… std={cp[key][\"std\"]}Ã… min={cp[key][\"min\"]}Ã… max={cp[key][\"max\"]}Ã…')\n",
        "                if 'details' in cp[key]:\n",
        "                    for d in cp[key]['details']:\n",
        "                        print(f'    pos{d[\"pos\"]}: {d[\"aa_a\"]}â†”{d[\"aa_b\"]} = {d[\"dist\"]}Ã…')\n",
        "    \n",
        "    # 4. Crossing Angle\n",
        "    ca = calculate_crossing_angle(pdb)\n",
        "    print(f'\\n[Crossing Angle]')\n",
        "    if ca:\n",
        "        print(f'  Angle: {ca[\"crossing_angle\"]}Â°')\n",
        "        print(f'  Orientation: {ca[\"orientation\"]}')\n",
        "        print(f'  DSSP used: {ca[\"dssp_used\"]}')\n",
        "    \n",
        "    # 5. SASA\n",
        "    sasa = analyze_sasa(pdb, seq)\n",
        "    print(f'\\n[SASA by GGRL type]')\n",
        "    if sasa:\n",
        "        for t in ['gon', 'gam', 'ri', 'geon']:\n",
        "            if t in sasa:\n",
        "                print(f'  {t}: mean={sasa[t][\"mean\"]} (n={sasa[t][\"n\"]})')\n",
        "        if 'naitae_order' in sasa:\n",
        "            print(f'  ë‚˜ì´í…Œ ìˆœì„œ (ê³¤<ë¦¬<ê±´): {\"âœ…\" if sasa[\"naitae_order\"] else \"âŒ\"}')\n",
        "    \n",
        "    all_results[name] = {\n",
        "        'oligomeric': oligo,\n",
        "        'salt_bridges': sb,\n",
        "        'core_packing': cp,\n",
        "        'crossing_angle': ca,\n",
        "        'sasa': sasa\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: íŒì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ìµœì¢… íŒì •\n",
        "# ============================================================\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print('=== Phase 5b-2 ColabFold Multimer â€” ìµœì¢… íŒì • ===')\n",
        "print('='*60)\n",
        "\n",
        "r = all_results\n",
        "\n",
        "# === íŒì • 1: ê³¤ ì½”ì–´ ì›ë¦¬ ===\n",
        "print('\\n[1] ê³¤ ì½”ì–´ ì›ë¦¬')\n",
        "try:\n",
        "    b_dd = r['B_GON']['core_packing']['d_d']['mean']\n",
        "    a_dd = r['A_WT']['core_packing']['d_d']['mean']\n",
        "    c_dd = r['C_GEON']['core_packing']['d_d']['mean']\n",
        "    gon_pass = b_dd < a_dd < c_dd\n",
        "    print(f'  dâ†”d\\' mean: B={b_dd}Ã… < A={a_dd}Ã… < C={c_dd}Ã…')\n",
        "    print(f'  â†’ {\"PASS âœ…\" if gon_pass else \"FAIL âŒ\"}')\n",
        "except:\n",
        "    print('  â†’ ë°ì´í„° ë¶€ì¡±')\n",
        "    gon_pass = False\n",
        "\n",
        "# === íŒì • 2: ê±´ í‘œë©´ ì›ë¦¬ ===\n",
        "print('\\n[2] ê±´ í‘œë©´ ì›ë¦¬')\n",
        "try:\n",
        "    a_sb = r['A_WT']['salt_bridges']['regular_count']\n",
        "    b_sb = r['B_GON']['salt_bridges']['regular_count']\n",
        "    c_sb = r['C_GEON']['salt_bridges']['regular_count']\n",
        "    c_sb_irreg = r['C_GEON']['salt_bridges']['irregular_count']\n",
        "    # ìˆ˜ì •ëœ ê¸°ì¤€: A â‰¥ C â‰¥ B ë˜ëŠ” C > A â‰¥ B\n",
        "    geon_pass = (a_sb >= b_sb) and (c_sb + c_sb_irreg >= b_sb)\n",
        "    print(f'  Regular salt bridges: A={a_sb}, B={b_sb}, C={c_sb}')\n",
        "    print(f'  C irregular: {c_sb_irreg}')\n",
        "    print(f'  â†’ {\"PASS âœ…\" if geon_pass else \"FAIL âŒ\"}')\n",
        "except:\n",
        "    print('  â†’ ë°ì´í„° ë¶€ì¡±')\n",
        "    geon_pass = False\n",
        "\n",
        "# === íŒì • 3: ê· í˜• ì„¤ê³„ ì¡°ê±´ ===\n",
        "print('\\n[3] ê· í˜• ì„¤ê³„ ì¡°ê±´')\n",
        "try:\n",
        "    a_angle = r['A_WT']['crossing_angle']['crossing_angle']\n",
        "    balance_pass = 15 <= a_angle <= 28\n",
        "    print(f'  WT crossing angle: {a_angle}Â° (ê¸°ì¤€: 18-25Â°)')\n",
        "    print(f'  â†’ {\"PASS âœ…\" if balance_pass else \"FAIL âŒ\"}')\n",
        "except:\n",
        "    print('  â†’ ë°ì´í„° ë¶€ì¡±')\n",
        "    balance_pass = False\n",
        "\n",
        "# === íŒì • 4: C ê·¸ë£¹ oligomeric state ===\n",
        "print('\\n[4] C ê·¸ë£¹ dimer ìœ ì§€ ì—¬ë¶€')\n",
        "try:\n",
        "    c_state = r['C_GEON']['oligomeric']['state']\n",
        "    c_contacts = r['C_GEON']['oligomeric']['contacts_8A']\n",
        "    print(f'  State: {c_state}')\n",
        "    print(f'  Contacts (8Ã…): {c_contacts}')\n",
        "    if 'SEPARATED' in c_state:\n",
        "        print(f'  â†’ CëŠ” dimer ìœ ì§€ ì‹¤íŒ¨ (monomer-like collapse)')\n",
        "    elif 'WEAK' in c_state:\n",
        "        print(f'  â†’ CëŠ” ì•½í•œ dimer (ê±´ ê³¼ë‹¤ â†’ ë¶ˆì•ˆì •)')\n",
        "    else:\n",
        "        print(f'  â†’ CëŠ” dimer ìœ ì§€')\n",
        "except:\n",
        "    print('  â†’ ë°ì´í„° ë¶€ì¡±')\n",
        "\n",
        "# === íŒì • 5: SASA ë‚˜ì´í…Œ ===\n",
        "print('\\n[5] SASA ë‚˜ì´í…Œ (ê³¤ < ë¦¬ < ê±´)')\n",
        "try:\n",
        "    a_sasa = r['A_WT']['sasa']\n",
        "    naitae = a_sasa.get('naitae_order', False)\n",
        "    print(f'  WT: ê³¤={a_sasa[\"gon\"][\"mean\"]}, ë¦¬={a_sasa.get(\"ri\",{}).get(\"mean\",\"N/A\")}, ê±´={a_sasa[\"geon\"][\"mean\"]}')\n",
        "    print(f'  â†’ {\"PASS âœ…\" if naitae else \"FAIL âŒ\"}')\n",
        "except:\n",
        "    print('  â†’ ë°ì´í„° ë¶€ì¡±')\n",
        "\n",
        "# === ì¢…í•© ===\n",
        "print('\\n' + '='*60)\n",
        "total_pass = sum([gon_pass, geon_pass, balance_pass])\n",
        "print(f'ì¢…í•©: {total_pass}/3 í•µì‹¬ íŒì • PASS')\n",
        "if total_pass == 3:\n",
        "    print('\\nğŸ‰ Phase 5b-2 ì™„ë£Œ!')\n",
        "    print('â†’ ê³¤ ì½”ì–´ / ê±´ í‘œë©´ / ê· í˜• ì„¤ê³„ 3ì›ë¦¬ ê³ ì •')\n",
        "    print('â†’ Phase 5c (Î²-sheet dimer) ì§„í–‰ ê°€ëŠ¥')\n",
        "else:\n",
        "    print(f'\\nâš ï¸ {3-total_pass}ê°œ í•­ëª© ì¶”ê°€ ê²€ì¦ í•„ìš”')\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²°ê³¼ ì €ì¥\n",
        "with open('gcn4_colabfold/phase5b2_colabfold_results.json', 'w') as f:\n",
        "    json.dump(all_results, f, indent=2, default=str)\n",
        "\n",
        "print('Results saved to gcn4_colabfold/phase5b2_colabfold_results.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: ì‹œê°í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "groups = ['A_WT', 'B_GON', 'C_GEON']\n",
        "labels = ['A (WT)', 'B (ê³¤â†‘)', 'C (ê±´â†‘)']\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
        "\n",
        "# Plot 1: dâ†”d' CÎ² distances\n",
        "ax = axes[0]\n",
        "dd_means = []\n",
        "dd_stds = []\n",
        "for g in groups:\n",
        "    if g in all_results and all_results[g]['core_packing'] and 'd_d' in all_results[g]['core_packing']:\n",
        "        dd_means.append(all_results[g]['core_packing']['d_d']['mean'])\n",
        "        dd_stds.append(all_results[g]['core_packing']['d_d']['std'])\n",
        "    else:\n",
        "        dd_means.append(0)\n",
        "        dd_stds.append(0)\n",
        "\n",
        "bars = ax.bar(labels, dd_means, yerr=dd_stds, color=colors, capsize=5, edgecolor='black', linewidth=0.5)\n",
        "ax.axhspan(5, 8, alpha=0.1, color='green', label='Normal range')\n",
        "ax.set_ylabel('dâ†”d\\' CÎ²-CÎ² Distance (Ã…)')\n",
        "ax.set_title('Core Packing (ê³¤ ì½”ì–´)')\n",
        "ax.legend()\n",
        "\n",
        "# Plot 2: Salt bridges\n",
        "ax = axes[1]\n",
        "sb_regular = []\n",
        "sb_irregular = []\n",
        "for g in groups:\n",
        "    if g in all_results and all_results[g]['salt_bridges']:\n",
        "        sb_regular.append(all_results[g]['salt_bridges']['regular_count'])\n",
        "        sb_irregular.append(all_results[g]['salt_bridges']['irregular_count'])\n",
        "    else:\n",
        "        sb_regular.append(0)\n",
        "        sb_irregular.append(0)\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "ax.bar(x, sb_regular, 0.4, label='Regular (eâ†”g\\')', color=colors, edgecolor='black', linewidth=0.5)\n",
        "ax.bar(x, sb_irregular, 0.4, bottom=sb_regular, label='Irregular', color=[c+'80' for c in colors], edgecolor='black', linewidth=0.5, alpha=0.5)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_ylabel('Salt Bridge Count')\n",
        "ax.set_title('Salt Bridges (ê±´ í‘œë©´)')\n",
        "ax.legend()\n",
        "\n",
        "# Plot 3: Crossing angle\n",
        "ax = axes[2]\n",
        "angles = []\n",
        "for g in groups:\n",
        "    if g in all_results and all_results[g]['crossing_angle']:\n",
        "        angles.append(all_results[g]['crossing_angle']['crossing_angle'])\n",
        "    else:\n",
        "        angles.append(0)\n",
        "\n",
        "ax.bar(labels, angles, color=colors, edgecolor='black', linewidth=0.5)\n",
        "ax.axhspan(18, 25, alpha=0.15, color='green', label='Normal range (18-25Â°)')\n",
        "ax.set_ylabel('Crossing Angle (Â°)')\n",
        "ax.set_title('Helix Crossing (ê· í˜•)')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('gcn4_colabfold/phase5b2_summary.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print('Figure saved.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
